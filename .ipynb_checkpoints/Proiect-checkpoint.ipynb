{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8bfbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.base_dir = ''\n",
    "        self.dir_pos_examples = os.path.join(self.base_dir, 'exemplePozitive')\n",
    "        self.dir_neg_examples = os.path.join(self.base_dir, 'exempleNegative')\n",
    "        self.dir_test_examples = (\"validare/validare/\")\n",
    "        self.path_annotations = (\"validare/validare_annotations.txt\")\n",
    "        self.sol_path=\"rezultate/\"\n",
    "        \n",
    "        self.dir_save_files = os.path.join(self.base_dir, 'salveazaFisiere')\n",
    "        if not os.path.exists(self.dir_save_files):\n",
    "            os.makedirs(self.dir_save_files)\n",
    "            print('directory created: {} '.format(self.dir_save_files))\n",
    "        else:\n",
    "            print('directory {} exists '.format(self.dir_save_files))\n",
    "\n",
    "        # set the parameters\n",
    "        self.dim_window_height=48\n",
    "        self.dim_window_width=48\n",
    "        self.dim_hog_cell = 12  # dimensiunea celulei\n",
    "        self.dim_descriptor_cell = 36  # dimensiunea descriptorului unei celule\n",
    "        self.overlap = 0.3\n",
    "        self.number_positive_examples = 6977  # numarul exemplelor pozitive\n",
    "        self.number_negative_examples = 18000  # numarul exemplelor negative\n",
    "        self.overlap = 0.3\n",
    "        self.has_annotations = True\n",
    "        self.threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec90699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import pdb\n",
    "import pickle\n",
    "import ntpath\n",
    "from copy import deepcopy\n",
    "import timeit\n",
    "import os\n",
    "from skimage.feature import hog\n",
    "\n",
    "\n",
    "class FacialDetector:\n",
    "    def __init__(self, params:Parameters):\n",
    "        self.params = params\n",
    "        self.best_model = None\n",
    "\n",
    "        \n",
    "        \n",
    "    def rescale_bbox(self,bbox, from_scale, to_scale):\n",
    "        rescaled_bbox = [int(coord * to_scale / from_scale) for coord in bbox]\n",
    "        return rescaled_bbox\n",
    "    \n",
    "    def resize_to_specific_size(self,image, target_width, target_height):\n",
    "        resized_image = cv.resize(image, (target_width, target_height))\n",
    "\n",
    "        return resized_image\n",
    "    \n",
    "    \n",
    "    def rescale_image(self,image, scale_factor):\n",
    "        new_width = int(image.shape[1] * scale_factor)\n",
    "        new_height = int(image.shape[0] * scale_factor)\n",
    "\n",
    "        rescaled_image = cv.resize(image, (new_width, new_height))\n",
    "\n",
    "        return rescaled_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def intersection_over_union(self, bbox_a, bbox_b):\n",
    "        x_a = max(bbox_a[0], bbox_b[0])\n",
    "        y_a = max(bbox_a[1], bbox_b[1])\n",
    "        x_b = min(bbox_a[2], bbox_b[2])\n",
    "        y_b = min(bbox_a[3], bbox_b[3])\n",
    "\n",
    "        inter_area = max(0, x_b - x_a + 1) * max(0, y_b - y_a + 1)\n",
    "\n",
    "        box_a_area = (bbox_a[2] - bbox_a[0] + 1) * (bbox_a[3] - bbox_a[1] + 1)\n",
    "        box_b_area = (bbox_b[2] - bbox_b[0] + 1) * (bbox_b[3] - bbox_b[1] + 1)\n",
    "\n",
    "        iou = inter_area / float(box_a_area + box_b_area - inter_area)\n",
    "\n",
    "        return iou\n",
    "    \n",
    "\n",
    "\n",
    "    def train_classifier(self, training_examples, train_labels,person=None):\n",
    "        svm_file_name = os.path.join(self.params.dir_save_files, 'best_model_%d_%d_%d' %\n",
    "                                     (self.params.dim_hog_cell, self.params.number_negative_examples,\n",
    "                                      self.params.number_positive_examples))\n",
    "        if person:\n",
    "            svm_file_name+=\"_\"+person\n",
    "        if os.path.exists(svm_file_name):\n",
    "            self.best_model = pickle.load(open(svm_file_name, 'rb'))\n",
    "            return\n",
    "\n",
    "        best_accuracy = 0\n",
    "        best_c = 0\n",
    "        best_model = None\n",
    "        Cs = [10 ** -5, 10 ** -4,  10 ** -3,  10 ** -2, 10 ** -1,1]\n",
    "        for c in Cs:\n",
    "            print('Antrenam un clasificator pentru c=%f' % c)\n",
    "            model = LinearSVC(C=c)\n",
    "            model.fit(training_examples, train_labels)\n",
    "            acc = model.score(training_examples, train_labels)\n",
    "            print(acc)\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_c = c\n",
    "                best_model = deepcopy(model)\n",
    "                \n",
    "        \n",
    "                \n",
    "\n",
    "        print('Performanta clasificatorului optim pt c = %f' % best_c)\n",
    "        # salveaza clasificatorul\n",
    "        pickle.dump(best_model, open(svm_file_name, 'wb'))\n",
    "\n",
    "        # vizualizeaza cat de bine sunt separate exemplele pozitive de cele negative dupa antrenare\n",
    "        # ideal ar fi ca exemplele pozitive sa primeasca scoruri > 0, iar exemplele negative sa primeasca scoruri < 0\n",
    "        scores = best_model.decision_function(training_examples)\n",
    "        self.best_model = best_model\n",
    "        positive_scores = scores[train_labels > 0]\n",
    "        negative_scores = scores[train_labels <= 0]\n",
    "        \n",
    "\n",
    "\n",
    "        plt.plot(np.sort(positive_scores))\n",
    "        plt.plot(np.zeros(len(positive_scores)))\n",
    "        plt.plot(np.sort(negative_scores))\n",
    "        plt.xlabel('Nr example antrenare')\n",
    "        plt.ylabel('Scor clasificator')\n",
    "        plt.title('Distributia scorurilor clasificatorului pe exemplele de antrenare')\n",
    "        plt.legend(['Scoruri exemple pozitive', '0', 'Scoruri exemple negative'])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    def non_maximal_suppression(self, image_detections, image_scores, image_size):\n",
    "        \"\"\"\n",
    "        Detectiile cu scor mare suprima detectiile ce se suprapun cu acestea dar au scor mai mic.\n",
    "        Detectiile se pot suprapune partial, dar centrul unei detectii nu poate\n",
    "        fi in interiorul celeilalte detectii.\n",
    "        :param image_detections:  numpy array de dimensiune NX4, unde N este numarul de detectii.\n",
    "        :param image_scores: numpy array de dimensiune N\n",
    "        :param image_size: tuplu, dimensiunea imaginii\n",
    "        :return: image_detections si image_scores care sunt maximale.\n",
    "        \"\"\"\n",
    "\n",
    "        # xmin, ymin, xmax, ymax\n",
    "        x_out_of_bounds = np.where(image_detections[:, 2] > image_size[1])[0]\n",
    "        y_out_of_bounds = np.where(image_detections[:, 3] > image_size[0])[0]\n",
    "        #print(x_out_of_bounds, y_out_of_bounds)\n",
    "        image_detections[x_out_of_bounds, 2] = image_size[1]\n",
    "        image_detections[y_out_of_bounds, 3] = image_size[0]\n",
    "        sorted_indices = np.flipud(np.argsort(image_scores))\n",
    "        sorted_image_detections = image_detections[sorted_indices]\n",
    "        sorted_scores = image_scores[sorted_indices]\n",
    "\n",
    "        is_maximal = np.ones(len(image_detections)).astype(bool)\n",
    "        iou_threshold = 0.3\n",
    "        for i in range(len(sorted_image_detections) - 1):\n",
    "            if is_maximal[i] == True:  # don't change to 'is True' because is a numpy True and is not a python True :)\n",
    "                for j in range(i + 1, len(sorted_image_detections)):\n",
    "                    if is_maximal[j] == True:  # don't change to 'is True' because is a numpy True and is not a python True :)\n",
    "                        if self.intersection_over_union(sorted_image_detections[i],sorted_image_detections[j]) > iou_threshold:is_maximal[j] = False\n",
    "                        else:  # verificam daca centrul detectiei este in mijlocul detectiei cu scor mai mare\n",
    "                            c_x = (sorted_image_detections[j][0] + sorted_image_detections[j][2]) / 2\n",
    "                            c_y = (sorted_image_detections[j][1] + sorted_image_detections[j][3]) / 2\n",
    "                            if sorted_image_detections[i][0] <= c_x <= sorted_image_detections[i][2] and \\\n",
    "                                    sorted_image_detections[i][1] <= c_y <= sorted_image_detections[i][3]:\n",
    "                                is_maximal[j] = False\n",
    "        return sorted_image_detections[is_maximal], sorted_scores[is_maximal]\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Aceasta functie returneaza toate detectiile ( = ferestre) pentru toate imaginile din self.params.dir_test_examples\n",
    "        Directorul cu numele self.params.dir_test_examples contine imagini ce\n",
    "        pot sau nu contine fete. Aceasta functie ar trebui sa detecteze fete atat pe setul de\n",
    "        date MIT+CMU dar si pentru alte imagini\n",
    "        Functia 'non_maximal_suppression' suprimeaza detectii care se suprapun (protocolul de evaluare considera o detectie duplicata ca fiind falsa)\n",
    "        Suprimarea non-maximelor se realizeaza pe pentru fiecare imagine.\n",
    "        :return:\n",
    "        detections: numpy array de dimensiune NX4, unde N este numarul de detectii pentru toate imaginile.\n",
    "        detections[i, :] = [x_min, y_min, x_max, y_max]\n",
    "        scores: numpy array de dimensiune N, scorurile pentru toate detectiile pentru toate imaginile.\n",
    "        file_names: numpy array de dimensiune N, pentru fiecare detectie trebuie sa salvam numele imaginii.\n",
    "        (doar numele, nu toata calea).\n",
    "        \"\"\"\n",
    "        scales=[1.         ,0.87055,    0.75785828, 0.66069345, 0.57622779, 0.50270779,\n",
    " 0.43855988, 0.38239679, 0.33287077, 0.28877435, 0.2499512,  0.21516408,\n",
    " 0.18401213, 0.15607649, 0.13190697]\n",
    "\n",
    "        test_images_path = os.path.join(self.params.dir_test_examples, '*.jpg')\n",
    "        test_files = glob.glob(test_images_path)\n",
    "        detections = None  # array cu toate detectiile pe care le obtinem\n",
    "        scores = np.array([])  # array cu toate scorurile pe care le obtinem\n",
    "        file_names = np.array([])  # array cu fisiele, in aceasta lista fisierele vor aparea de mai multe ori, pentru fiecare\n",
    "        # detectie din imagine, numele imaginii va aparea in aceasta lista\n",
    "        w = self.best_model.coef_.T\n",
    "        bias = self.best_model.intercept_[0]\n",
    "        num_test_images = len(test_files)\n",
    "        descriptors_to_return = []\n",
    "        for i in range(num_test_images):\n",
    "            start_time = timeit.default_timer()\n",
    "            print('Procesam imaginea de testare %d/%d..' % (i, num_test_images))\n",
    "            img = cv.imread(test_files[i], cv.IMREAD_GRAYSCALE)\n",
    "            img_c=img\n",
    "            image_scores = np.array([])\n",
    "            image_detections = np.array([])\n",
    "            for scale in scales:\n",
    "                img=self.rescale_image(img_c,scale)\n",
    "                hog_descriptors = hog(img, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                                      cells_per_block=(2, 2), feature_vector=False)\n",
    "                num_cols = img.shape[1] // self.params.dim_hog_cell -1\n",
    "                num_rows = img.shape[0] // self.params.dim_hog_cell -1\n",
    "                num_cell_in_template_height = self.params.dim_window_height // self.params.dim_hog_cell-1\n",
    "                num_cell_in_template_width= self.params.dim_window_width // self.params.dim_hog_cell-1 \n",
    "                \n",
    "\n",
    "                for y in range(0, num_rows - num_cell_in_template_height):\n",
    "                    for x in range(0, num_cols - num_cell_in_template_width):\n",
    "                        descr = hog_descriptors[y:y + num_cell_in_template_height, x:x + num_cell_in_template_width].flatten()\n",
    "                        score = np.dot(descr, w)[0] + bias\n",
    "                        if score > self.params.threshold:\n",
    "                            x_min = int(x * self.params.dim_hog_cell)\n",
    "                            y_min = int(y * self.params.dim_hog_cell)\n",
    "                            x_max = int(x * self.params.dim_hog_cell + self.params.dim_window)\n",
    "                            y_max = int(y * self.params.dim_hog_cell + self.params.dim_window)\n",
    "                            box=[x_min,y_min,x_max,y_max]\n",
    "                            new_box=self.rescale_bbox(box,scale,1)\n",
    "                            if image_detections.size>0:\n",
    "                                image_detections=np.vstack([image_detections,new_box])\n",
    "                            else:\n",
    "                                image_detections=np.array([new_box])\n",
    "                            image_scores=np.append(image_scores,score)\n",
    "            if len(image_scores) > 0:\n",
    "                image_detections, image_scores = self.non_maximal_suppression(np.array(image_detections),\n",
    "                                                                              np.array(image_scores), img_c.shape)\n",
    "                \n",
    "                \n",
    "            if len(image_scores) > 0:\n",
    "                if detections is None:\n",
    "                    detections = image_detections\n",
    "                else:\n",
    "                    detections = np.concatenate((detections, image_detections))\n",
    "                scores = np.append(scores, image_scores)\n",
    "                short_name = ntpath.basename(test_files[i])\n",
    "                image_names = [short_name for ww in range(len(image_scores))]\n",
    "                file_names = np.append(file_names, image_names)\n",
    "\n",
    "            end_time = timeit.default_timer()\n",
    "            print('Timpul de procesarea al imaginii de testare %d/%d este %f sec.'\n",
    "                  % (i, num_test_images, end_time - start_time))\n",
    "\n",
    "        return detections, scores, file_names\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    def my_check_train(self):\n",
    "        num_images = 4000\n",
    "        all_boxes=[]\n",
    "        negative_examples=[]\n",
    "        num_negative_per_image = self.params.number_negative_examples // num_images\n",
    "        people=[\"fred\",\"barney\",\"wilma\",\"betty\"]\n",
    "        for person in people:\n",
    "            i=1\n",
    "            j=0\n",
    "            folder_path = f\"{self.params.base_dir}{person}\"\n",
    "            annotations_path=f\"{self.params.base_dir}{person}_annotations.txt\"\n",
    "            with open(annotations_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "            files = os.listdir(folder_path)\n",
    "            patches=[]\n",
    "            for file in files:\n",
    "                c=0\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                img=cv.imread(file_path)\n",
    "                boxes=[]\n",
    "                i_str=str(i)\n",
    "                while len(i_str)<4:\n",
    "                    i_str=\"0\"+i_str\n",
    "                while j<len(lines) and lines[j][0:4]==i_str:\n",
    "                    box=lines[j].split()[1:5]\n",
    "                    for m in range(len(box)):\n",
    "                        box[m]=int(box[m])\n",
    "                    boxes.append(box)\n",
    "                    j+=1\n",
    "                i+=1\n",
    "                all_boxes.append(boxes)\n",
    "        return all_boxes\n",
    "        \n",
    "   \n",
    "    \n",
    "\n",
    "    def get_poz_person_descriptors(self,person):\n",
    "        positive_descriptors=[]\n",
    "        path=self.params.dir_pos_examples\n",
    "        images=os.listdir(path)\n",
    "        for image in images:\n",
    "            if image.split(\".\")[0].split(\"_\")[1]==person:\n",
    "                full_path=os.path.join(path,image)\n",
    "                img=cv.imread(full_path,cv.IMREAD_GRAYSCALE)\n",
    "                features = hog(img, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                               cells_per_block=(2, 2), feature_vector=True)\n",
    "                positive_descriptors.append(features)\n",
    "                \n",
    "                if self.params.use_flip_images:\n",
    "                    features = hog(np.fliplr(img), pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                                   cells_per_block=(2, 2), feature_vector=True)\n",
    "                    positive_descriptors.append(features)\n",
    "        return np.array(positive_descriptors)\n",
    "    \n",
    "    def get_neg_person_descriptors(self,person,negative=[]):\n",
    "        negative_descriptors=[]\n",
    "        path=self.params.dir_pos_examples\n",
    "        images=os.listdir(path)\n",
    "        i=0\n",
    "        for image in images:\n",
    "            if image.split(\".\")[0].split(\"_\")[1]!=person:\n",
    "                full_path=os.path.join(path,image)\n",
    "                img=cv.imread(full_path,cv.IMREAD_GRAYSCALE)\n",
    "                features = hog(img, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                               cells_per_block=(2, 2), feature_vector=True)\n",
    "                negative_descriptors.append(features)\n",
    "                \n",
    "                if self.params.use_flip_images:\n",
    "                    features = hog(np.fliplr(img), pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                                   cells_per_block=(2, 2), feature_vector=True)\n",
    "                    negative_descriptors.append(features)\n",
    "        negative_descriptors=np.array(negative_descriptors)\n",
    "        if len(negative)!=0:\n",
    "            negative_descriptors = np.concatenate((negative_descriptors, negative), axis=0)\n",
    "        return (negative_descriptors)\n",
    "    '''\n",
    "    def train_recognisition(self):\n",
    "    \n",
    "    def face_recognition(self,detections):\n",
    "    '''\n",
    "        \n",
    "        \n",
    "    def run_person(self,detections,file_names):\n",
    "        \"\"\"\n",
    "        Aceasta functie returneaza toate detectiile ( = ferestre) pentru toate imaginile din self.params.dir_test_examples\n",
    "        Directorul cu numele self.params.dir_test_examples contine imagini ce\n",
    "        pot sau nu contine fete. Aceasta functie ar trebui sa detecteze fete atat pe setul de\n",
    "        date MIT+CMU dar si pentru alte imagini\n",
    "        Functia 'non_maximal_suppression' suprimeaza detectii care se suprapun (protocolul de evaluare considera o detectie duplicata ca fiind falsa)\n",
    "        Suprimarea non-maximelor se realizeaza pe pentru fiecare imagine.\n",
    "        :return:\n",
    "        detections: numpy array de dimensiune NX4, unde N este numarul de detectii pentru toate imaginile.\n",
    "        detections[i, :] = [x_min, y_min, x_max, y_max]\n",
    "        scores: numpy array de dimensiune N, scorurile pentru toate detectiile pentru toate imaginile.\n",
    "        file_names: numpy array de dimensiune N, pentru fiecare detectie trebuie sa salvam numele imaginii.\n",
    "        (doar numele, nu toata calea).\n",
    "        \"\"\"\n",
    "        scales=[1.         ,0.87055,    0.75785828, 0.66069345, 0.57622779, 0.50270779,\n",
    " 0.43855988, 0.38239679, 0.33287077, 0.28877435, 0.2499512,  0.21516408,\n",
    " 0.18401213, 0.15607649, 0.13190697]\n",
    "\n",
    "        test_images_path = (self.params.dir_test_examples)\n",
    "        detections_new = None  # array cu toate detectiile pe care le obtinem\n",
    "        scores = np.array([])  # array cu toate scorurile pe care le obtinem\n",
    "        file_names_new = np.array([])  # array cu fisiele, in aceasta lista fisierele vor aparea de mai multe ori, pentru fiecare\n",
    "        # detectie din imagine, numele imaginii va aparea in aceasta lista\n",
    "        w = self.best_model.coef_.T\n",
    "        bias = self.best_model.intercept_[0]\n",
    "        num_test_images = len(detections)\n",
    "        descriptors_to_return = []\n",
    "        i=0\n",
    "        while i < (detections.shape[0]):\n",
    "            path=os.path.join(test_images_path,file_names[i])\n",
    "            start_time = timeit.default_timer()\n",
    "            print('Procesam imaginea de testare %d/%d..' % (i, num_test_images))\n",
    "            img = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "            aux=file_names[i]\n",
    "            while i<detections.shape[0] and file_names[i]==aux:\n",
    "                image_scores = np.array([])\n",
    "                image_detections = np.array([])\n",
    "                x_min, y_min, x_max, y_max=detections[i]\n",
    "                img_run=img[y_min:y_max,x_min:x_max]\n",
    "                img_c=img_run\n",
    "                ok=False\n",
    "                for scale in scales:\n",
    "                    if ok:\n",
    "                        break\n",
    "                    img_cop=self.rescale_image(img_c,scale)\n",
    "                    hog_descriptors = hog(img_run, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                                          cells_per_block=(2, 2), feature_vector=False)\n",
    "                    num_cols = img_run.shape[1] // self.params.dim_hog_cell -1\n",
    "                    num_rows = img_run.shape[0] // self.params.dim_hog_cell -1\n",
    "                    num_cell_in_template_height = self.params.dim_window_height // self.params.dim_hog_cell-1\n",
    "                    num_cell_in_template_width= self.params.dim_window_width // self.params.dim_hog_cell-1 \n",
    "                    for y in range(0, num_rows - num_cell_in_template_height):\n",
    "                        if ok:\n",
    "                            break\n",
    "                        for x in range(0, num_cols - num_cell_in_template_width):\n",
    "                            descr = hog_descriptors[y:y + num_cell_in_template_height, x:x + num_cell_in_template_width].flatten()\n",
    "                            score = np.dot(descr, w)[0] + bias\n",
    "                            if score > self.params.threshold:\n",
    "                                '''\n",
    "                                x_min = int(x * self.params.dim_hog_cell)\n",
    "                                y_min = int(y * self.params.dim_hog_cell)\n",
    "                                x_max = int(x * self.params.dim_hog_cell + self.params.dim_window)\n",
    "                                y_max = int(y * self.params.dim_hog_cell + self.params.dim_window)\n",
    "                                '''\n",
    "                                new_box=[x_min,y_min,x_max,y_max]\n",
    "                                #cv.imshow()\n",
    "                                ok=True\n",
    "                                if image_detections.size>0:\n",
    "                                    image_detections=np.vstack([image_detections,new_box])\n",
    "                                else:\n",
    "                                    image_detections=np.array([new_box])\n",
    "                                image_scores=np.append(image_scores,score)\n",
    "                                break\n",
    "\n",
    "\n",
    "                if len(image_scores) > 0:\n",
    "                    if detections_new is None:\n",
    "                        detections_new = image_detections\n",
    "                    else:\n",
    "                        detections_new = np.concatenate((detections_new, image_detections))\n",
    "                    scores = np.append(scores, image_scores)\n",
    "                    short_name = ntpath.basename(file_names[i])\n",
    "                    image_names = [short_name for ww in range(len(image_scores))]\n",
    "                    file_names_new = np.append(file_names_new, image_names)\n",
    "                \n",
    "                i+=1\n",
    "\n",
    "\n",
    "                end_time = timeit.default_timer()\n",
    "                print('Timpul de procesarea al imaginii de testare %d/%d este %f sec.'\n",
    "                      % (i, num_test_images, end_time - start_time))\n",
    "\n",
    "        return detections_new, scores, file_names_new\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b08a3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory salveazaFisiere exists \n",
      "salveazaFisiere\\descriptoriExemplePozitive_6_13954.npy\n",
      "Am incarcat descriptorii pentru exemplele pozitive 13954\n",
      "Am incarcat descriptorii pentru exemplele negative\n",
      "Positive Features Shape: (13954, 900)\n",
      "Negative Features Shape: (72283, 900)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rezultate/task1/detections_all_faces.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20008\\3661263309.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[0mdetections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfacial_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msol_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"task1/detections_all_faces.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetections\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msol_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"task1/scores_all_faces.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msol_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"task1/file_names_all_faces.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[0mfile_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rezultate/task1/detections_all_faces.npy'"
     ]
    }
   ],
   "source": [
    "params: Parameters = Parameters()\n",
    "params.dim_window=36\n",
    "params.dim_window_width = 36\n",
    "params.dim_window_height = 36# exemplele pozitive (fete de oameni cropate) au 36x36 pixeli\n",
    "params.dim_hog_cell = 6  # dimensiunea celulei\n",
    "params.overlap = 0.3\n",
    "params.number_positive_examples = 6977  # numarul exemplelor pozitive\n",
    "params.number_negative_examples = 72283  # numarul exemplelor negative\n",
    "\n",
    "params.threshold = 0 # toate ferestrele cu scorul > threshold si maxime locale devin detectii\n",
    "params.has_annotations = True\n",
    "\n",
    "params.use_hard_mining = False  # (optional)antrenare cu exemple puternic negative\n",
    "params.use_flip_images = True  # adauga imaginile cu fete oglindite\n",
    "\n",
    "if params.use_flip_images:\n",
    "    params.number_positive_examples *= 2\n",
    "\n",
    "facial_detector: FacialDetector = FacialDetector(params)\n",
    "#good=facial_detector.get_positive_examples()\n",
    "#bad=facial_detector.get_negative_examples()\n",
    "#print(len(good),len(bad))\n",
    "\n",
    "# Pasii 1+2+3. Incarcam exemplele pozitive (cropate) si exemple negative generate\n",
    "# verificam daca sunt deja existente\n",
    "positive_features_path = os.path.join(params.dir_save_files, 'descriptoriExemplePozitive_' + str(params.dim_hog_cell) + '_' +\n",
    "                        str(params.number_positive_examples) + '.npy')\n",
    "if os.path.exists(positive_features_path):\n",
    "    positive_features = np.load(positive_features_path)\n",
    "    print('Am incarcat descriptorii pentru exemplele pozitive',len(positive_features))\n",
    "\n",
    "# exemple negative\n",
    "negative_features_path = os.path.join(params.dir_save_files, 'descriptoriExempleNegative_' + str(params.dim_hog_cell) + '_' +\n",
    "                        str(params.number_negative_examples) + '.npy')\n",
    "if os.path.exists(negative_features_path):\n",
    "    negative_features = np.load(negative_features_path)\n",
    "    print('Am incarcat descriptorii pentru exemplele negative')\n",
    "\n",
    "# Pasul 4. Invatam clasificatorul liniar\n",
    "print(\"Positive Features Shape:\", np.squeeze(positive_features).shape)\n",
    "print(\"Negative Features Shape:\", np.squeeze(negative_features).shape)\n",
    "\n",
    "training_examples = np.concatenate((np.squeeze(positive_features), np.squeeze(negative_features)), axis=0)\n",
    "train_labels = np.concatenate((np.ones(positive_features.shape[0]), np.zeros(np.array(negative_features).shape[0])))\n",
    "#print(len(np.ones(params.number_positive_examples)), len(np.zeros(negative_features.shape[0])))\n",
    "facial_detector.train_classifier(training_examples, train_labels)\n",
    "\n",
    "# Pasul 5. (optional) Antrenare cu exemple puternic negative (detectii cu scor >0 din cele 274 de imagini negative)\n",
    "# Daca implementati acest pas ar trebui sa modificati functia FacialDetector.run()\n",
    "# astfel incat sa va returneze descriptorii detectiilor cu scor > 0 din cele 274 imagini negative\n",
    "# completati codul in continuare\n",
    "# TODO:  (optional)  completeaza codul in continuare\n",
    "\n",
    "detections, scores, file_names = facial_detector.run()\n",
    "np.save(os.path.join(params.sol_path, \"task1/detections_all_faces.npy\"), detections)\n",
    "np.save(os.path.join(params.sol_path, \"task1/scores_all_faces.npy\"), scores)\n",
    "np.save(os.path.join(params.sol_path, \"task1/file_names_all_faces.npy\"), file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147eca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(person):\n",
    "    params.dir_pos_examples=os.path.join(params.base_dir, \"exemplePozitive\")\n",
    "    if person ==\"fred\":\n",
    "        params.dim_window_width = 36\n",
    "        params.dim_window_height = 48\n",
    "        params.number_positive_examples=2\n",
    "        params.dim_hog_cell=6\n",
    "        params.number_negative_examples =  67511\n",
    "    if person ==\"barney\":\n",
    "        params.dim_window_width = 36\n",
    "        params.dim_window_height = 36\n",
    "        params.number_positive_examples=13954\n",
    "        params.dim_hog_cell=6\n",
    "        params.number_negative_examples =  72283\n",
    "    if person ==\"wilma\":\n",
    "        params.dim_window_width = 36\n",
    "        params.dim_window_height = 48\n",
    "        params.number_positive_examples=1\n",
    "        params.dim_hog_cell=4\n",
    "        params.number_negative_examples =  67511\n",
    "    if person ==\"betty\":\n",
    "        params.dim_window_width = 36\n",
    "        params.dim_window_height = 48\n",
    "        params.number_positive_examples=1\n",
    "        params.dim_hog_cell=4\n",
    "        params.number_negative_examples =  67511\n",
    "        \n",
    "    params.threshold=0\n",
    "    positive_features_path = os.path.join(params.dir_save_files, 'descriptoriExemplePozitive_' +person+'_'+ str(params.dim_hog_cell) + '_' +\n",
    "                            str(params.number_positive_examples) + '.npy')\n",
    "    if os.path.exists(positive_features_path):\n",
    "        positive_features_2 = np.load(positive_features_path)\n",
    "        print('Am incarcat descriptorii pentru exemplele pozitive',len(positive_features))\n",
    "    else:\n",
    "        print('Construim descriptorii pentru exemplele pozitive:')\n",
    "        positive_features_2 = facial_detector.get_poz_person_descriptors(person)\n",
    "        np.save(positive_features_path, positive_features_2)\n",
    "        print('Am salvat descriptorii pentru exemplele pozitive in fisierul %s' % positive_features_path)\n",
    "        \n",
    "        \n",
    "    print((np.squeeze(positive_features_2).shape,\"aici\"))\n",
    "    # exemple negative\n",
    "    negative_features_path = os.path.join(params.dir_save_files, 'descriptoriExempleNegative_' +person+'_'+ str(params.dim_hog_cell) + '_' +\n",
    "                            str(params.number_negative_examples) + '.npy')\n",
    "    if os.path.exists(negative_features_path):\n",
    "        negative_features_2 = np.load(negative_features_path)\n",
    "        print('Am incarcat descriptorii pentru exemplele negative')\n",
    "    else:\n",
    "        print('Construim descriptorii pentru exemplele negative:')\n",
    "        negative_features_2 = facial_detector.get_neg_person_descriptors(person,negative_features)\n",
    "        np.save(negative_features_path, negative_features_2)\n",
    "        print('Am salvat descriptorii pentru exemplele negative in fisierul %s' % negative_features_path)\n",
    "        \n",
    "    print((np.squeeze(negative_features_2).shape,\"aici\"))\n",
    "    \n",
    "    training_examples = np.concatenate((np.squeeze(positive_features_2), np.squeeze(negative_features_2)), axis=0)\n",
    "    train_labels = np.concatenate((np.ones(positive_features_2.shape[0]), np.zeros(np.array(negative_features_2).shape[0])))\n",
    "    facial_detector.train_classifier(training_examples, train_labels,person)\n",
    "    detections2, scores2, file_names2 = facial_detector.run()\n",
    "    np.save(os.path.join(params.sol_path, f\"task2/detections_{person}.npy\"), detections2)\n",
    "    np.save(os.path.join(params.sol_path, f\"task2/scores_{person}.npy\"), scores2)\n",
    "    np.save(os.path.join(params.sol_path, f\"task2/file_names_{person}.npy\"), file_names2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(\"fred\")\n",
    "run(\"barney\")\n",
    "run(\"betty\")\n",
    "run(\"wilma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb670bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_run_2(person):\n",
    "    net = cv.dnn.readNet(\"salveazaFisiere/yolov4-flintstone_last_2.weights\", \"salveazaFisiere/yolov4-flintstone-2.cfg\")\n",
    "    classes = []\n",
    "    with open(\"C:/Users/rares/darknet/data/obj.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "    validation_folder = params.dir_test_examples\n",
    "    detections = None  # array cu toate detectiile pe care le obtinem\n",
    "    scores = np.array([])  # array cu toate scorurile pe care le obtinem\n",
    "    file_names = np.array([])\n",
    "    \n",
    "    test_images_path = os.path.join(params.dir_test_examples, '*.jpg')\n",
    "    test_files = glob.glob(test_images_path)\n",
    "    i=0\n",
    "\n",
    "    for file in os.listdir(validation_folder):\n",
    "        start_time = timeit.default_timer()\n",
    "        image_path = os.path.join(validation_folder, file)\n",
    "        img = cv.imread(image_path)\n",
    "        height, width, _ = img.shape\n",
    "        blob = cv.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(layer_names)\n",
    "        image_scores = np.array([])\n",
    "        image_detections = np.array([])\n",
    "\n",
    "        # Process the output\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                result = detection[5:]\n",
    "                class_id = np.argmax(result)\n",
    "                confidence = result[class_id]\n",
    "                if confidence > 0.0 and classes[class_id]==person:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x_min = max(0, int(center_x - w / 2))\n",
    "                    y_min = max(0, int(center_y - h / 2))\n",
    "                    x_max = min(width, int(center_x + w / 2))\n",
    "                    y_max = min(height, int(center_y + h / 2))\n",
    "\n",
    "                    box=[x_min,y_min,x_max,y_max]\n",
    "                    #cv.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                    #cv.putText(img, classes[class_id], (x_min, y_min - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    if image_detections.size>0:\n",
    "                        image_detections=np.vstack([image_detections,box])\n",
    "                    else:\n",
    "                        image_detections=np.array([box])\n",
    "                    image_scores=np.append(image_scores,confidence)\n",
    "        if len(image_scores) > 0:\n",
    "            image_detections, image_scores = facial_detector.non_maximal_suppression(np.array(image_detections),\n",
    "                                                                          np.array(image_scores), img.shape)\n",
    "\n",
    "        \n",
    "        if len(image_scores) > 0:\n",
    "            if detections is None:\n",
    "                detections = image_detections\n",
    "            else:\n",
    "                detections = np.concatenate((detections, image_detections))\n",
    "            scores = np.append(scores, image_scores)\n",
    "            short_name = ntpath.basename(test_files[i])\n",
    "            image_names = [short_name for ww in range(len(image_scores))]\n",
    "            file_names = np.append(file_names, image_names)\n",
    "        i+=1\n",
    "        end_time = timeit.default_timer()\n",
    "        print('Timpul de procesarea al imaginii de testare %d/%d este %f sec.'\n",
    "              % (i,200, end_time - start_time))\n",
    "        \n",
    "    np.save(os.path.join(params.sol_path, f\"bonus_task2/detections_{person}.npy\"), detections)\n",
    "    np.save(os.path.join(params.sol_path, f\"bonus_task2/scores_{person}.npy\"), scores)\n",
    "    np.save(os.path.join(params.sol_path, f\"bonus_task2/file_names_{person}.npy\"), file_names)\n",
    "\n",
    "\n",
    "    return detections, scores, file_names\n",
    "                          \n",
    "                     \n",
    "yolo_run_2(\"Fred\")\n",
    "yolo_run_2(\"Barney\")\n",
    "yolo_run_2(\"Wilma\")\n",
    "yolo_run_2(\"Betty\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_run_1():\n",
    "    net = cv.dnn.readNet(\"salveazaFisiere/yolov4-flintstone-1_1000.weights\", \"salveazaFisiere/yolov4-flintstone-1.cfg\")\n",
    "    classes = []\n",
    "    with open(\"C:/Users/rares/darknet/data/obj.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "    validation_folder = params.dir_test_examples\n",
    "    detections = None  # array cu toate detectiile pe care le obtinem\n",
    "    scores = np.array([])  # array cu toate scorurile pe care le obtinem\n",
    "    file_names = np.array([])\n",
    "    \n",
    "    test_images_path = os.path.join(params.dir_test_examples, '*.jpg')\n",
    "    test_files = glob.glob(test_images_path)\n",
    "    i=0\n",
    "\n",
    "    for file in os.listdir(validation_folder):\n",
    "        start_time = timeit.default_timer()\n",
    "        image_path = os.path.join(validation_folder, file)\n",
    "        img = cv.imread(image_path)\n",
    "        height, width, _ = img.shape\n",
    "        blob = cv.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(layer_names)\n",
    "        image_scores = np.array([])\n",
    "        image_detections = np.array([])\n",
    "\n",
    "        # Process the output\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                result = detection[5:]\n",
    "                class_id = np.argmax(result)\n",
    "                confidence = result[class_id]\n",
    "                if confidence > 0.0:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x_min = max(0, int(center_x - w / 2))\n",
    "                    y_min = max(0, int(center_y - h / 2))\n",
    "                    x_max = min(width, int(center_x + w / 2))\n",
    "                    y_max = min(height, int(center_y + h / 2))\n",
    "\n",
    "                    box=[x_min,y_min,x_max,y_max]\n",
    "                    #cv.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                    #cv.putText(img, classes[class_id], (x_min, y_min - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    if image_detections.size>0:\n",
    "                        image_detections=np.vstack([image_detections,box])\n",
    "                    else:\n",
    "                        image_detections=np.array([box])\n",
    "                    image_scores=np.append(image_scores,confidence)\n",
    "        if len(image_scores) > 0:\n",
    "            image_detections, image_scores = facial_detector.non_maximal_suppression(np.array(image_detections),\n",
    "                                                                          np.array(image_scores), img.shape)\n",
    "\n",
    "        \n",
    "        if len(image_scores) > 0:\n",
    "            if detections is None:\n",
    "                detections = image_detections\n",
    "            else:\n",
    "                detections = np.concatenate((detections, image_detections))\n",
    "            scores = np.append(scores, image_scores)\n",
    "            short_name = ntpath.basename(test_files[i])\n",
    "            image_names = [short_name for ww in range(len(image_scores))]\n",
    "            file_names = np.append(file_names, image_names)\n",
    "        i+=1\n",
    "        end_time = timeit.default_timer()\n",
    "        print('Timpul de procesarea al imaginii de testare %d/%d este %f sec.'\n",
    "              % (i,200, end_time - start_time))\n",
    "\n",
    "\n",
    "    np.save(os.path.join(params.sol_path, f\"bonus_task1/detections.npy\"), detections)\n",
    "    np.save(os.path.join(params.sol_path, f\"bonus_task1/scores.npy\"), scores)\n",
    "    np.save(os.path.join(params.sol_path, f\"bonus_task1/file_names.npy\"), file_names)\n",
    "    return detections, scores, file_names\n",
    "                                     \n",
    "yolo_run_1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
