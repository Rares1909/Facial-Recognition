{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bbox_inside(inner_bbox, outer_bbox):\n",
    "    \"\"\"\n",
    "    Check if the inner bounding box is completely inside the outer bounding box.\n",
    "\n",
    "    Parameters:\n",
    "    - inner_bbox: Tuple (x_min, y_min, x_max, y_max) representing the inner bounding box.\n",
    "    - outer_bbox: Tuple (x_min, y_min, x_max, y_max) representing the outer bounding box.\n",
    "\n",
    "    Returns:\n",
    "    - True if inner_bbox is inside outer_bbox, False otherwise.\n",
    "    \"\"\"\n",
    "    inner_x_min, inner_y_min, inner_x_max, inner_y_max = inner_bbox\n",
    "    outer_x_min, outer_y_min, outer_x_max, outer_y_max = outer_bbox\n",
    "\n",
    "    # Check if inner_bbox is inside outer_bbox\n",
    "    return (\n",
    "        inner_x_min >= outer_x_min and\n",
    "        inner_y_min >= outer_y_min and\n",
    "        inner_x_max <= outer_x_max and\n",
    "        inner_y_max <= outer_y_max\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.base_dir = 'antrenare/'\n",
    "        self.dir_pos_examples = os.path.join(self.base_dir, 'exemplePozitive')\n",
    "        self.dir_neg_examples = os.path.join(self.base_dir, 'exempleNegative')\n",
    "        self.dir_test_examples = (\"validare/validare/\")\n",
    "        self.path_annotations = (\"validare/validare_annotations.txt\")\n",
    "        self.sol_path=\"C:/Users/rares/Desktop/CAVA/Proiect2/rezultate/\"\n",
    "        \n",
    "        self.dir_save_files = os.path.join(self.base_dir, 'salveazaFisiere')\n",
    "        if not os.path.exists(self.dir_save_files):\n",
    "            os.makedirs(self.dir_save_files)\n",
    "            print('directory created: {} '.format(self.dir_save_files))\n",
    "        else:\n",
    "            print('directory {} exists '.format(self.dir_save_files))\n",
    "\n",
    "        # set the parameters\n",
    "        self.dim_window_height=48\n",
    "        self.dim_window_width=48\n",
    "        self.dim_hog_cell = 12  # dimensiunea celulei\n",
    "        self.dim_descriptor_cell = 36  # dimensiunea descriptorului unei celule\n",
    "        self.overlap = 0.3\n",
    "        self.number_positive_examples = 6977  # numarul exemplelor pozitive\n",
    "        self.number_negative_examples = 18000  # numarul exemplelor negative\n",
    "        self.overlap = 0.3\n",
    "        self.has_annotations = True\n",
    "        self.threshold = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d943063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import pdb\n",
    "import pickle\n",
    "import ntpath\n",
    "from copy import deepcopy\n",
    "import timeit\n",
    "import os\n",
    "from skimage.feature import hog\n",
    "\n",
    "\n",
    "class FacialDetector:\n",
    "    def __init__(self, params:Parameters):\n",
    "        self.params = params\n",
    "        self.best_model = None\n",
    "\n",
    "        \n",
    "        \n",
    "    def rescale_bbox(self,bbox, from_scale, to_scale):\n",
    "        rescaled_bbox = [int(coord * to_scale / from_scale) for coord in bbox]\n",
    "        return rescaled_bbox\n",
    "    \n",
    "    def resize_to_specific_size(self,image, target_width, target_height):\n",
    "        # Resize the image to the specified size\n",
    "        resized_image = cv.resize(image, (target_width, target_height))\n",
    "\n",
    "        return resized_image\n",
    "    \n",
    "    \n",
    "    def rescale_image(self,image, scale_factor):\n",
    "        # Calculate the new dimensions after rescaling\n",
    "        new_width = int(image.shape[1] * scale_factor)\n",
    "        new_height = int(image.shape[0] * scale_factor)\n",
    "\n",
    "        # Resize the image\n",
    "        rescaled_image = cv.resize(image, (new_width, new_height))\n",
    "\n",
    "        return rescaled_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def intersection_over_union(self, bbox_a, bbox_b):\n",
    "        x_a = max(bbox_a[0], bbox_b[0])\n",
    "        y_a = max(bbox_a[1], bbox_b[1])\n",
    "        x_b = min(bbox_a[2], bbox_b[2])\n",
    "        y_b = min(bbox_a[3], bbox_b[3])\n",
    "\n",
    "        inter_area = max(0, x_b - x_a + 1) * max(0, y_b - y_a + 1)\n",
    "\n",
    "        box_a_area = (bbox_a[2] - bbox_a[0] + 1) * (bbox_a[3] - bbox_a[1] + 1)\n",
    "        box_b_area = (bbox_b[2] - bbox_b[0] + 1) * (bbox_b[3] - bbox_b[1] + 1)\n",
    "\n",
    "        iou = inter_area / float(box_a_area + box_b_area - inter_area)\n",
    "\n",
    "        return iou\n",
    "\n",
    "\n",
    "    def get_positive_examples(self):\n",
    "        count=1\n",
    "        positive_examples=[]\n",
    "        people=[\"barney\",\"fred\",\"wilma\",\"betty\"]\n",
    "        for person in people:\n",
    "            i=1\n",
    "            j=0\n",
    "            folder_path = f\"{self.params.base_dir}{person}\"\n",
    "            annotations_path=f\"{self.params.base_dir}{person}_annotations.txt\"\n",
    "            with open(annotations_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "            files = os.listdir(folder_path)\n",
    "            for file in files:\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                img=cv.imread(file_path)\n",
    "                i_str=str(i)\n",
    "                while len(i_str)<4:\n",
    "                    i_str=\"0\"+i_str\n",
    "                while j<len(lines) and lines[j][0:4]==i_str:\n",
    "                    if lines[j].split()[5]!=\"\":\n",
    "                        poz=lines[j].split()[1:5]\n",
    "                        for q in range(len(poz)):\n",
    "                            poz[q]=int(poz[q])\n",
    "                        xmin,ymin,xmax,ymax=poz\n",
    "                        image_patch = img[(ymin):(ymax), (xmin):(xmax)]\n",
    "                        image_patch=self.resize_to_specific_size(image_patch,self.params.dim_window_width,self.params.dim_window_height)\n",
    "                        positive_examples.append(image_patch)\n",
    "                        patch_filename = f\"{count}_{lines[j].split()[-1]}.jpg\" \n",
    "                        patch_filepath = os.path.join(self.params.dir_pos_examples, patch_filename)\n",
    "                        cv.imwrite(patch_filepath, image_patch)\n",
    "                        count+=1\n",
    "\n",
    "                    j+=1\n",
    "\n",
    "\n",
    "                i+=1\n",
    "        return positive_examples\n",
    "\n",
    "    def get_negative_examples(self):\n",
    "        num_images = 4000\n",
    "        negative_examples=[]\n",
    "        num_negative_per_image = self.params.number_negative_examples // num_images\n",
    "        people=[\"wilma\",\"barney\",\"fred\",\"betty\"]\n",
    "        for person in people:\n",
    "            i=1\n",
    "            j=0\n",
    "            folder_path = f\"{self.params.base_dir}{person}\"\n",
    "            annotations_path=f\"{self.params.base_dir}{person}_annotations.txt\"\n",
    "            with open(annotations_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "            files = os.listdir(folder_path)\n",
    "            patches=[]\n",
    "            for file in files:\n",
    "                c=0\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                img=cv.imread(file_path)\n",
    "                boxes=[]\n",
    "                i_str=str(i)\n",
    "                while len(i_str)<4:\n",
    "                    i_str=\"0\"+i_str\n",
    "                while j<len(lines) and lines[j][0:4]==i_str:\n",
    "                    box=lines[j].split()[1:5]\n",
    "                    for m in range(len(box)):\n",
    "                        box[m]=int(box[m])\n",
    "                    boxes.append(box)\n",
    "                    j+=1\n",
    "                i+=1\n",
    "\n",
    "                num_rows = img.shape[0]\n",
    "                num_cols = img.shape[1]\n",
    "                x = np.random.randint(low=0, high=num_cols - self.params.dim_window_width, size=num_negative_per_image)\n",
    "                y = np.random.randint(low=0, high=num_rows - self.params.dim_window_height, size=num_negative_per_image)\n",
    "                for idx in range(len(y)):\n",
    "                    c=0\n",
    "                    patch =[x[idx],y[idx], x[idx]+self.params.dim_window_width,y[idx] + self.params.dim_window_height]\n",
    "                    p=[]\n",
    "                    nr=0\n",
    "                    for box in boxes:\n",
    "                        p.append(self.intersection_over_union(box,patch))\n",
    "                    for v in p:\n",
    "                        if v<0.05:\n",
    "                            nr+=1\n",
    "                    while nr!=len(boxes):\n",
    "                                p=[]\n",
    "                                nr=0\n",
    "                                if c==50000:\n",
    "                                    print(1)\n",
    "                                    break\n",
    "                                a = np.random.randint(low=0, high=num_cols - self.params.dim_window_width)\n",
    "                                b = np.random.randint(low=0, high=num_rows - self.params.dim_window_height)\n",
    "                                patch=[a,b,a+self.params.dim_window_width,b+self.params.dim_window_height]\n",
    "                                for box in boxes:\n",
    "                                    p.append(self.intersection_over_union(box,patch))\n",
    "                                for v in p:\n",
    "                                    if v<0.05:\n",
    "                                        nr+=1\n",
    "                                c+=1\n",
    "                    if c==50000:\n",
    "                        continue\n",
    "                    patch_img=img[patch[1]:patch[3],patch[0]:patch[2]]\n",
    "                    negative_examples.append(patch_img)\n",
    "                    patch_filename = f\"{i}{idx}{person}.jpg\" \n",
    "                    patch_filepath = os.path.join(self.params.dir_neg_examples, patch_filename)\n",
    "                    cv.imwrite(patch_filepath, patch_img)\n",
    "        return negative_examples\n",
    "\n",
    "    \n",
    "    \n",
    "    def rotate_image_30_degrees(self,image,angle):\n",
    "        # Read the image\n",
    "\n",
    "        # Get image shape\n",
    "        rows, cols = image.shape\n",
    "\n",
    "        # Define the rotation angle (30 degrees)\n",
    "        angle = 30\n",
    "\n",
    "        # Calculate the rotation matrix\n",
    "        rotation_matrix = cv.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "\n",
    "        # Apply the rotation to the image\n",
    "        rotated_image = cv.warpAffine(image, rotation_matrix, (cols, rows))\n",
    "\n",
    "        return rotated_image\n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    def get_positive_descriptors(self):\n",
    "        # in aceasta functie calculam descriptorii pozitivi\n",
    "        # vom returna un numpy array de dimensiuni NXD\n",
    "        # unde N - numar exemplelor pozitive\n",
    "        # iar D - dimensiunea descriptorului\n",
    "        # D = (params.dim_window/params.dim_hog_cell - 1) ^ 2 * params.dim_descriptor_cell (fetele sunt patrate)\n",
    "\n",
    "        images_path = os.path.join(self.params.dir_pos_examples, '*.jpg')\n",
    "        files = glob.glob(images_path)\n",
    "        num_images = len(files)\n",
    "        positive_descriptors = []\n",
    "        print('Calculam descriptorii pt %d imagini pozitive...' % num_images)\n",
    "        for i in range(num_images):\n",
    "            print('Procesam exemplul pozitiv numarul %d...' % i)\n",
    "            img = cv.imread(files[i], cv.IMREAD_GRAYSCALE)\n",
    "            # TODO: sterge\n",
    "            features = hog(img, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                           cells_per_block=(2, 2), feature_vector=True)\n",
    "            print(len(features))\n",
    "\n",
    "            positive_descriptors.append(features)\n",
    "            if self.params.use_flip_images:\n",
    "                features = hog(np.fliplr(img), pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                               cells_per_block=(2, 2), feature_vector=True)\n",
    "                positive_descriptors.append(features)\n",
    "                '''\n",
    "                features = hog(np.fliplr(self.rotate_image_30_degrees(img,30)), pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                               cells_per_block=(2, 2), feature_vector=True)\n",
    "                positive_descriptors.append(features)\n",
    "                \n",
    "                features = hog(np.fliplr(self.rotate_image_30_degrees(img,30)), pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                               cells_per_block=(2, 2), feature_vector=True)\n",
    "                positive_descriptors.append(features)\n",
    "             \n",
    "            features=hog(self.rotate_image_30_degrees(img,30), pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                               cells_per_block=(2, 2), feature_vector=True)\n",
    "            positive_descriptors.append(features)\n",
    "            \n",
    "            features=hog(self.rotate_image_30_degrees(img,270), pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                               cells_per_block=(2, 2), feature_vector=True)\n",
    "            '''\n",
    "            \n",
    "\n",
    "        positive_descriptors = np.array(positive_descriptors)\n",
    "        return positive_descriptors\n",
    "\n",
    "    def get_negative_descriptors(self):\n",
    "        # in aceasta functie calculam descriptorii negativi\n",
    "        # vom returna un numpy array de dimensiuni NXD\n",
    "        # unde N - numar exemplelor negative\n",
    "        # iar D - dimensiunea descriptorului\n",
    "        # avem 274 de imagini negative, vream sa avem self.params.number_negative_examples (setat implicit cu 10000)\n",
    "        # de exemple negative, din fiecare imagine vom genera aleator self.params.number_negative_examples // 274\n",
    "        # patch-uri de dimensiune 36x36 pe care le vom considera exemple negative\n",
    "\n",
    "        images_path = os.path.join(self.params.dir_neg_examples, '*.jpg')\n",
    "        files = glob.glob(images_path)\n",
    "        num_images = len(files)\n",
    "        num_negative_per_image = self.params.number_negative_examples // num_images\n",
    "        negative_descriptors = []\n",
    "        print('Calculam descriptorii pt %d imagini negative' % num_images)\n",
    "        for i in range(num_images):\n",
    "            print('Procesam exemplul negativ numarul %d...' % i)\n",
    "            img = cv.imread(files[i], cv.IMREAD_GRAYSCALE)\n",
    "            descr = hog(img, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                        cells_per_block=(2, 2), feature_vector=False)\n",
    "            negative_descriptors.append(descr.flatten())\n",
    "        negative_descriptors = np.array(negative_descriptors)\n",
    "        return negative_descriptors\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_extra_descriptors(self):\n",
    "    # in aceasta functie calculam descriptorii pozitivi\n",
    "    # vom returna un numpy array de dimensiuni NXD\n",
    "    # unde N - numar exemplelor pozitive\n",
    "    # iar D - dimensiunea descriptorului\n",
    "    # D = (params.dim_window/params.dim_hog_cell - 1) ^ 2 * params.dim_descriptor_cell (fetele sunt patrate)\n",
    "\n",
    "        images_path = os.path.join(f\"{self.params.base_dir}/extra_test1\", '*.jpg')\n",
    "        files = glob.glob(images_path)\n",
    "        num_images = len(files)\n",
    "        extra_descriptors = []\n",
    "        print('Calculam descriptorii pt %d imagini negative + extra...' % num_images)\n",
    "        for i in range(num_images):\n",
    "            print('Procesam exemplul pozitiv numarul %d...' % i)\n",
    "            img = cv.imread(files[i], cv.IMREAD_GRAYSCALE)\n",
    "            # TODO: sterge\n",
    "            features = hog(img, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                           cells_per_block=(2, 2), feature_vector=True)\n",
    "            print(len(features))\n",
    "\n",
    "            extra_descriptors.append(features)\n",
    "        return extra_descriptors\n",
    "\n",
    "    def train_classifier(self, training_examples, train_labels,person=None):\n",
    "        svm_file_name = os.path.join(self.params.dir_save_files, 'best_model_%d_%d_%d' %\n",
    "                                     (self.params.dim_hog_cell, self.params.number_negative_examples,\n",
    "                                      self.params.number_positive_examples))\n",
    "        if person:\n",
    "            svm_file_name+=\"_\"+person\n",
    "        if os.path.exists(svm_file_name):\n",
    "            self.best_model = pickle.load(open(svm_file_name, 'rb'))\n",
    "            return\n",
    "\n",
    "        best_accuracy = 0\n",
    "        best_c = 0\n",
    "        best_model = None\n",
    "        Cs = [10 ** -5, 10 ** -4,  10 ** -3,  10 ** -2, 10 ** -1,1]\n",
    "        for c in Cs:\n",
    "            print('Antrenam un clasificator pentru c=%f' % c)\n",
    "            model = LinearSVC(C=c)\n",
    "            model.fit(training_examples, train_labels)\n",
    "            acc = model.score(training_examples, train_labels)\n",
    "            print(acc)\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_c = c\n",
    "                best_model = deepcopy(model)\n",
    "                \n",
    "        \n",
    "                \n",
    "\n",
    "        print('Performanta clasificatorului optim pt c = %f' % best_c)\n",
    "        # salveaza clasificatorul\n",
    "        pickle.dump(best_model, open(svm_file_name, 'wb'))\n",
    "\n",
    "        # vizualizeaza cat de bine sunt separate exemplele pozitive de cele negative dupa antrenare\n",
    "        # ideal ar fi ca exemplele pozitive sa primeasca scoruri > 0, iar exemplele negative sa primeasca scoruri < 0\n",
    "        scores = best_model.decision_function(training_examples)\n",
    "        self.best_model = best_model\n",
    "        positive_scores = scores[train_labels > 0]\n",
    "        negative_scores = scores[train_labels <= 0]\n",
    "        \n",
    "\n",
    "\n",
    "        plt.plot(np.sort(positive_scores))\n",
    "        plt.plot(np.zeros(len(positive_scores)))\n",
    "        plt.plot(np.sort(negative_scores))\n",
    "        plt.xlabel('Nr example antrenare')\n",
    "        plt.ylabel('Scor clasificator')\n",
    "        plt.title('Distributia scorurilor clasificatorului pe exemplele de antrenare')\n",
    "        plt.legend(['Scoruri exemple pozitive', '0', 'Scoruri exemple negative'])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    def non_maximal_suppression(self, image_detections, image_scores, image_size):\n",
    "        \"\"\"\n",
    "        Detectiile cu scor mare suprima detectiile ce se suprapun cu acestea dar au scor mai mic.\n",
    "        Detectiile se pot suprapune partial, dar centrul unei detectii nu poate\n",
    "        fi in interiorul celeilalte detectii.\n",
    "        :param image_detections:  numpy array de dimensiune NX4, unde N este numarul de detectii.\n",
    "        :param image_scores: numpy array de dimensiune N\n",
    "        :param image_size: tuplu, dimensiunea imaginii\n",
    "        :return: image_detections si image_scores care sunt maximale.\n",
    "        \"\"\"\n",
    "\n",
    "        # xmin, ymin, xmax, ymax\n",
    "        x_out_of_bounds = np.where(image_detections[:, 2] > image_size[1])[0]\n",
    "        y_out_of_bounds = np.where(image_detections[:, 3] > image_size[0])[0]\n",
    "        #print(x_out_of_bounds, y_out_of_bounds)\n",
    "        image_detections[x_out_of_bounds, 2] = image_size[1]\n",
    "        image_detections[y_out_of_bounds, 3] = image_size[0]\n",
    "        sorted_indices = np.flipud(np.argsort(image_scores))\n",
    "        sorted_image_detections = image_detections[sorted_indices]\n",
    "        sorted_scores = image_scores[sorted_indices]\n",
    "\n",
    "        is_maximal = np.ones(len(image_detections)).astype(bool)\n",
    "        iou_threshold = 0.3\n",
    "        for i in range(len(sorted_image_detections) - 1):\n",
    "            if is_maximal[i] == True:  # don't change to 'is True' because is a numpy True and is not a python True :)\n",
    "                for j in range(i + 1, len(sorted_image_detections)):\n",
    "                    if is_maximal[j] == True:  # don't change to 'is True' because is a numpy True and is not a python True :)\n",
    "                        if self.intersection_over_union(sorted_image_detections[i],sorted_image_detections[j]) > iou_threshold:is_maximal[j] = False\n",
    "                        else:  # verificam daca centrul detectiei este in mijlocul detectiei cu scor mai mare\n",
    "                            c_x = (sorted_image_detections[j][0] + sorted_image_detections[j][2]) / 2\n",
    "                            c_y = (sorted_image_detections[j][1] + sorted_image_detections[j][3]) / 2\n",
    "                            if sorted_image_detections[i][0] <= c_x <= sorted_image_detections[i][2] and \\\n",
    "                                    sorted_image_detections[i][1] <= c_y <= sorted_image_detections[i][3]:\n",
    "                                is_maximal[j] = False\n",
    "        return sorted_image_detections[is_maximal], sorted_scores[is_maximal]\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Aceasta functie returneaza toate detectiile ( = ferestre) pentru toate imaginile din self.params.dir_test_examples\n",
    "        Directorul cu numele self.params.dir_test_examples contine imagini ce\n",
    "        pot sau nu contine fete. Aceasta functie ar trebui sa detecteze fete atat pe setul de\n",
    "        date MIT+CMU dar si pentru alte imagini\n",
    "        Functia 'non_maximal_suppression' suprimeaza detectii care se suprapun (protocolul de evaluare considera o detectie duplicata ca fiind falsa)\n",
    "        Suprimarea non-maximelor se realizeaza pe pentru fiecare imagine.\n",
    "        :return:\n",
    "        detections: numpy array de dimensiune NX4, unde N este numarul de detectii pentru toate imaginile.\n",
    "        detections[i, :] = [x_min, y_min, x_max, y_max]\n",
    "        scores: numpy array de dimensiune N, scorurile pentru toate detectiile pentru toate imaginile.\n",
    "        file_names: numpy array de dimensiune N, pentru fiecare detectie trebuie sa salvam numele imaginii.\n",
    "        (doar numele, nu toata calea).\n",
    "        \"\"\"\n",
    "        scales=[1.         ,0.87055,    0.75785828, 0.66069345, 0.57622779, 0.50270779,\n",
    " 0.43855988, 0.38239679, 0.33287077, 0.28877435, 0.2499512,  0.21516408,\n",
    " 0.18401213, 0.15607649, 0.13190697]\n",
    "\n",
    "        test_images_path = os.path.join(self.params.dir_test_examples, '*.jpg')\n",
    "        test_files = glob.glob(test_images_path)\n",
    "        detections = None  # array cu toate detectiile pe care le obtinem\n",
    "        scores = np.array([])  # array cu toate scorurile pe care le obtinem\n",
    "        file_names = np.array([])  # array cu fisiele, in aceasta lista fisierele vor aparea de mai multe ori, pentru fiecare\n",
    "        # detectie din imagine, numele imaginii va aparea in aceasta lista\n",
    "        w = self.best_model.coef_.T\n",
    "        bias = self.best_model.intercept_[0]\n",
    "        num_test_images = len(test_files)\n",
    "        descriptors_to_return = []\n",
    "        for i in range(num_test_images):\n",
    "            start_time = timeit.default_timer()\n",
    "            print('Procesam imaginea de testare %d/%d..' % (i, num_test_images))\n",
    "            img = cv.imread(test_files[i], cv.IMREAD_GRAYSCALE)\n",
    "            img_c=img\n",
    "            image_scores = np.array([])\n",
    "            image_detections = np.array([])\n",
    "            for scale in scales:\n",
    "                img=self.rescale_image(img_c,scale)\n",
    "                hog_descriptors = hog(img, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                                      cells_per_block=(2, 2), feature_vector=False)\n",
    "                num_cols = img.shape[1] // self.params.dim_hog_cell -1\n",
    "                num_rows = img.shape[0] // self.params.dim_hog_cell -1\n",
    "                num_cell_in_template_height = self.params.dim_window_height // self.params.dim_hog_cell-1\n",
    "                num_cell_in_template_width= self.params.dim_window_width // self.params.dim_hog_cell-1 \n",
    "                \n",
    "\n",
    "                for y in range(0, num_rows - num_cell_in_template_height):\n",
    "                    for x in range(0, num_cols - num_cell_in_template_width):\n",
    "                        descr = hog_descriptors[y:y + num_cell_in_template_height, x:x + num_cell_in_template_width].flatten()\n",
    "                        score = np.dot(descr, w)[0] + bias\n",
    "                        if score > self.params.threshold:\n",
    "                            x_min = int(x * self.params.dim_hog_cell)\n",
    "                            y_min = int(y * self.params.dim_hog_cell)\n",
    "                            x_max = int(x * self.params.dim_hog_cell + self.params.dim_window)\n",
    "                            y_max = int(y * self.params.dim_hog_cell + self.params.dim_window)\n",
    "                            box=[x_min,y_min,x_max,y_max]\n",
    "                            new_box=self.rescale_bbox(box,scale,1)\n",
    "                            if image_detections.size>0:\n",
    "                                image_detections=np.vstack([image_detections,new_box])\n",
    "                            else:\n",
    "                                image_detections=np.array([new_box])\n",
    "                            image_scores=np.append(image_scores,score)\n",
    "            if len(image_scores) > 0:\n",
    "                image_detections, image_scores = self.non_maximal_suppression(np.array(image_detections),\n",
    "                                                                              np.array(image_scores), img_c.shape)\n",
    "                \n",
    "                \n",
    "            if len(image_scores) > 0:\n",
    "                if detections is None:\n",
    "                    detections = image_detections\n",
    "                else:\n",
    "                    detections = np.concatenate((detections, image_detections))\n",
    "                scores = np.append(scores, image_scores)\n",
    "                short_name = ntpath.basename(test_files[i])\n",
    "                image_names = [short_name for ww in range(len(image_scores))]\n",
    "                file_names = np.append(file_names, image_names)\n",
    "\n",
    "            end_time = timeit.default_timer()\n",
    "            print('Timpul de procesarea al imaginii de testare %d/%d este %f sec.'\n",
    "                  % (i, num_test_images, end_time - start_time))\n",
    "\n",
    "        return detections, scores, file_names\n",
    "\n",
    "    def compute_average_precision(self, rec, prec):\n",
    "        # functie adaptata din 2010 Pascal VOC development kit\n",
    "        m_rec = np.concatenate(([0], rec, [1]))\n",
    "        m_pre = np.concatenate(([0], prec, [0]))\n",
    "        for i in range(len(m_pre) - 1, -1, 1):\n",
    "            m_pre[i] = max(m_pre[i], m_pre[i + 1])\n",
    "        m_rec = np.array(m_rec)\n",
    "        i = np.where(m_rec[1:] != m_rec[:-1])[0] + 1\n",
    "        average_precision = np.sum((m_rec[i] - m_rec[i - 1]) * m_pre[i])\n",
    "        return average_precision\n",
    "\n",
    "    def eval_detections(self,detections, scores, file_names,ground_truth_path):\n",
    "        ground_truth_file = np.loadtxt(ground_truth_path, dtype='str')\n",
    "        ground_truth_file_names = np.array(ground_truth_file[:, 0])\n",
    "        ground_truth_detections = np.array(ground_truth_file[:, 1:], int)\n",
    "\n",
    "        num_gt_detections = len(ground_truth_detections)  # numar total de adevarat pozitive\n",
    "        gt_exists_detection = np.zeros(num_gt_detections)\n",
    "        # sorteazam detectiile dupa scorul lor\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        file_names = file_names[sorted_indices]\n",
    "        scores = scores[sorted_indices]\n",
    "        detections = detections[sorted_indices]\n",
    "\n",
    "        num_detections = len(detections)\n",
    "        true_positive = np.zeros(num_detections)\n",
    "        false_positive = np.zeros(num_detections)\n",
    "        duplicated_detections = np.zeros(num_detections)\n",
    "\n",
    "        for detection_idx in range(num_detections):\n",
    "            indices_detections_on_image = np.where(ground_truth_file_names == file_names[detection_idx])[0]\n",
    "\n",
    "            gt_detections_on_image = ground_truth_detections[indices_detections_on_image]\n",
    "            bbox = detections[detection_idx]\n",
    "            max_overlap = -1\n",
    "            index_max_overlap_bbox = -1\n",
    "            for gt_idx, gt_bbox in enumerate(gt_detections_on_image):\n",
    "                overlap = self.intersection_over_union(bbox, gt_bbox)\n",
    "                if overlap > max_overlap:\n",
    "                    max_overlap = overlap\n",
    "                    index_max_overlap_bbox = indices_detections_on_image[gt_idx]\n",
    "\n",
    "            # clasifica o detectie ca fiind adevarat pozitiva / fals pozitiva\n",
    "            if max_overlap >= 0.3:\n",
    "                if gt_exists_detection[index_max_overlap_bbox] == 0:\n",
    "                    true_positive[detection_idx] = 1\n",
    "                    gt_exists_detection[index_max_overlap_bbox] = 1\n",
    "                else:\n",
    "                    false_positive[detection_idx] = 1\n",
    "                    duplicated_detections[detection_idx] = 1\n",
    "            else:\n",
    "                false_positive[detection_idx] = 1\n",
    "\n",
    "        cum_false_positive = np.cumsum(false_positive)\n",
    "        cum_true_positive = np.cumsum(true_positive)\n",
    "\n",
    "        rec = cum_true_positive / num_gt_detections\n",
    "        prec = cum_true_positive / (cum_true_positive + cum_false_positive)\n",
    "        average_precision = self.compute_average_precision(rec, prec)\n",
    "        plt.plot(rec, prec, '-')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('All faces: average precision %.3f' % average_precision)\n",
    "        plt.savefig('precizie_medie_all_faces.png')\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def my_check_train(self):\n",
    "        num_images = 4000\n",
    "        all_boxes=[]\n",
    "        negative_examples=[]\n",
    "        num_negative_per_image = self.params.number_negative_examples // num_images\n",
    "        people=[\"fred\",\"barney\",\"wilma\",\"betty\"]\n",
    "        for person in people:\n",
    "            i=1\n",
    "            j=0\n",
    "            folder_path = f\"{self.params.base_dir}{person}\"\n",
    "            annotations_path=f\"{self.params.base_dir}{person}_annotations.txt\"\n",
    "            with open(annotations_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "            files = os.listdir(folder_path)\n",
    "            patches=[]\n",
    "            for file in files:\n",
    "                c=0\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                img=cv.imread(file_path)\n",
    "                boxes=[]\n",
    "                i_str=str(i)\n",
    "                while len(i_str)<4:\n",
    "                    i_str=\"0\"+i_str\n",
    "                while j<len(lines) and lines[j][0:4]==i_str:\n",
    "                    box=lines[j].split()[1:5]\n",
    "                    for m in range(len(box)):\n",
    "                        box[m]=int(box[m])\n",
    "                    boxes.append(box)\n",
    "                    j+=1\n",
    "                i+=1\n",
    "                all_boxes.append(boxes)\n",
    "        return all_boxes\n",
    "        \n",
    "    def run_train(self,all_boxes):\n",
    "        \"\"\"\n",
    "        Aceasta functie returneaza toate detectiile ( = ferestre) pentru toate imaginile din self.params.dir_test_examples\n",
    "        Directorul cu numele self.params.dir_test_examples contine imagini ce\n",
    "        pot sau nu contine fete. Aceasta functie ar trebui sa detecteze fete atat pe setul de\n",
    "        date MIT+CMU dar si pentru alte imagini\n",
    "        Functia 'non_maximal_suppression' suprimeaza detectii care se suprapun (protocolul de evaluare considera o detectie duplicata ca fiind falsa)\n",
    "        Suprimarea non-maximelor se realizeaza pe pentru fiecare imagine.\n",
    "        :return:\n",
    "        detections: numpy array de dimensiune NX4, unde N este numarul de detectii pentru toate imaginile.\n",
    "        detections[i, :] = [x_min, y_min, x_max, y_max]\n",
    "        scores: numpy array de dimensiune N, scorurile pentru toate detectiile pentru toate imaginile.\n",
    "        file_names: numpy array de dimensiune N, pentru fiecare detectie trebuie sa salvam numele imaginii.\n",
    "        (doar numele, nu toata calea).\n",
    "        \"\"\"\n",
    "        scales=[1.         ,0.87055,    0.75785828, 0.66069345, 0.57622779, 0.50270779,\n",
    "    0.43855988, 0.38239679, 0.33287077, 0.28877435, 0.2499512,  0.21516408]\n",
    "\n",
    "        #test_images_path = os.path.join(self.params.dir_test_examples, '*.jpg')\n",
    "        test_images_path=os.path.join(self.params.base_dir,\"fred\")\n",
    "        next=[\"\",\"barney\",\"wilma\",\"betty\"]\n",
    "        j=0\n",
    "        #test_files = glob.glob(test_images_path)\n",
    "        detections = None  # array cu toate detectiile pe care le obtinem\n",
    "        scores = np.array([])  # array cu toate scorurile pe care le obtinem\n",
    "        file_names = np.array([])  # array cu fisiele, in aceasta lista fisierele vor aparea de mai multe ori, pentru fiecare\n",
    "        # detectie din imagine, numele imaginii va aparea in aceasta lista\n",
    "        w = self.best_model.coef_.T\n",
    "        bias = self.best_model.intercept_[0]\n",
    "        #num_test_images = len(test_files)\n",
    "        num_test_images=4000\n",
    "        descriptors_to_return = []\n",
    "        test_files = os.listdir(test_images_path)\n",
    "        new_file=False\n",
    "        i=0\n",
    "        while j <4:\n",
    "            if i==999:\n",
    "                new_file=True\n",
    "\n",
    "            start_time = timeit.default_timer()\n",
    "            print('Procesam imaginea de testare %d/%d..' % (i, num_test_images))\n",
    "            img = cv.imread(os.path.join(test_images_path,test_files[i]), cv.IMREAD_GRAYSCALE)\n",
    "            img_c=img\n",
    "            image_scores = np.array([])\n",
    "            image_detections = np.array([])\n",
    "            for scale in scales:\n",
    "                img=self.rescale_image(img_c,scale)\n",
    "                hog_descriptors = hog(img, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                                      cells_per_block=(2, 2), feature_vector=False)\n",
    "                num_cols = img.shape[1] // self.params.dim_hog_cell -1\n",
    "                num_rows = img.shape[0] // self.params.dim_hog_cell -1\n",
    "                num_cell_in_template_height = self.params.dim_window_height // self.params.dim_hog_cell-1\n",
    "                num_cell_in_template_width= self.params.dim_window_width // self.params.dim_hog_cell-1 \n",
    "\n",
    "\n",
    "                for y in range(0, num_rows - num_cell_in_template_height):\n",
    "                    for x in range(0, num_cols - num_cell_in_template_width):\n",
    "                        descr = hog_descriptors[y:y + num_cell_in_template_height, x:x + num_cell_in_template_width].flatten()\n",
    "                        score = np.dot(descr, w)[0] + bias\n",
    "                        if score > self.params.threshold:\n",
    "                            x_min = int(x * self.params.dim_hog_cell)\n",
    "                            y_min = int(y * self.params.dim_hog_cell)\n",
    "                            x_max = int(x * self.params.dim_hog_cell + self.params.dim_window)\n",
    "                            y_max = int(y * self.params.dim_hog_cell + self.params.dim_window)\n",
    "                            box=[x_min,y_min,x_max,y_max]\n",
    "                            new_box=self.rescale_bbox(box,scale,1)\n",
    "                            if image_detections.size>0:\n",
    "                                image_detections=np.vstack([image_detections,new_box])\n",
    "                            else:\n",
    "                                image_detections=np.array([new_box])\n",
    "                            image_scores=np.append(image_scores,score)\n",
    "            if len(image_scores) > 0:\n",
    "                image_detections, image_scores = self.non_maximal_suppression(np.array(image_detections),\n",
    "                                                                              np.array(image_scores), img_c.shape)\n",
    "                \n",
    "            real=[]\n",
    "            for idx in range(len(image_detections)):\n",
    "                if image_scores[idx]>3:\n",
    "                    real.append(image_detections[idx])\n",
    "\n",
    "            nr=0\n",
    "            for bbox in real:\n",
    "                ok=False\n",
    "                for box in all_boxes[i+j*1000]:\n",
    "                    if(self.intersection_over_union(bbox,box)>0.15 or is_bbox_inside(bbox,box)):\n",
    "                        ok=True  \n",
    "                if ok==False:\n",
    "                    xmin,ymin,xmax,ymax=bbox\n",
    "                    image_patch = img_c[(ymin):(ymax), (xmin):(xmax)]\n",
    "                    image_patch=self.resize_to_specific_size(image_patch,self.params.dim_window_width,self.params.dim_window_height)\n",
    "                    patch_filename = f\"{i+j*1000}_{nr}.jpg\" \n",
    "                    patch_filepath = os.path.join(self.params.base_dir, f\"extra_test1/{patch_filename}\")\n",
    "                    #cv.imshow(\"\",image_patch)\n",
    "                    #cv.waitKey(0)\n",
    "                    cv.imwrite(patch_filepath, image_patch)\n",
    "                nr+=1\n",
    "                \n",
    "            if len(image_scores) > 0:\n",
    "                if detections is None:\n",
    "                    detections = image_detections\n",
    "                else:\n",
    "                    detections = np.concatenate((detections, image_detections))\n",
    "                scores = np.append(scores, image_scores)\n",
    "                short_name = ntpath.basename(test_files[i])\n",
    "                image_names = [short_name for ww in range(len(image_scores))]\n",
    "                file_names = np.append(file_names, image_names)\n",
    "\n",
    "            end_time = timeit.default_timer()\n",
    "            if new_file:\n",
    "                j+=1\n",
    "                test_images_path=os.path.join(self.params.base_dir,next[j])\n",
    "                test_files = os.listdir(test_images_path)\n",
    "                new_file=False\n",
    "                i=-1\n",
    "            i+=1\n",
    "            print('Timpul de procesarea al imaginii de testare %d/%d este %f sec.'\n",
    "                  % (i, num_test_images, end_time - start_time))\n",
    "\n",
    "        return detections, scores, file_names\n",
    "    \n",
    "    \n",
    "\n",
    "    def get_poz_person_descriptors(self,person):\n",
    "        positive_descriptors=[]\n",
    "        path=self.params.dir_pos_examples\n",
    "        images=os.listdir(path)\n",
    "        for image in images:\n",
    "            if image.split(\".\")[0].split(\"_\")[1]==person:\n",
    "                full_path=os.path.join(path,image)\n",
    "                img=cv.imread(full_path,cv.IMREAD_GRAYSCALE)\n",
    "                features = hog(img, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                               cells_per_block=(2, 2), feature_vector=True)\n",
    "                positive_descriptors.append(features)\n",
    "                \n",
    "                if self.params.use_flip_images:\n",
    "                    features = hog(np.fliplr(img), pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                                   cells_per_block=(2, 2), feature_vector=True)\n",
    "                    positive_descriptors.append(features)\n",
    "        return np.array(positive_descriptors)\n",
    "    \n",
    "    def get_neg_person_descriptors(self,person,negative=[]):\n",
    "        negative_descriptors=[]\n",
    "        path=self.params.dir_pos_examples\n",
    "        images=os.listdir(path)\n",
    "        i=0\n",
    "        for image in images:\n",
    "            if image.split(\".\")[0].split(\"_\")[1]!=person:\n",
    "                full_path=os.path.join(path,image)\n",
    "                img=cv.imread(full_path,cv.IMREAD_GRAYSCALE)\n",
    "                features = hog(img, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                               cells_per_block=(2, 2), feature_vector=True)\n",
    "                negative_descriptors.append(features)\n",
    "                \n",
    "                if self.params.use_flip_images:\n",
    "                    features = hog(np.fliplr(img), pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                                   cells_per_block=(2, 2), feature_vector=True)\n",
    "                    negative_descriptors.append(features)\n",
    "        negative_descriptors=np.array(negative_descriptors)\n",
    "        if len(negative)!=0:\n",
    "            negative_descriptors = np.concatenate((negative_descriptors, negative), axis=0)\n",
    "        return (negative_descriptors)\n",
    "    '''\n",
    "    def train_recognisition(self):\n",
    "    \n",
    "    def face_recognition(self,detections):\n",
    "    '''\n",
    "        \n",
    "        \n",
    "    def run_person(self,detections,file_names):\n",
    "        \"\"\"\n",
    "        Aceasta functie returneaza toate detectiile ( = ferestre) pentru toate imaginile din self.params.dir_test_examples\n",
    "        Directorul cu numele self.params.dir_test_examples contine imagini ce\n",
    "        pot sau nu contine fete. Aceasta functie ar trebui sa detecteze fete atat pe setul de\n",
    "        date MIT+CMU dar si pentru alte imagini\n",
    "        Functia 'non_maximal_suppression' suprimeaza detectii care se suprapun (protocolul de evaluare considera o detectie duplicata ca fiind falsa)\n",
    "        Suprimarea non-maximelor se realizeaza pe pentru fiecare imagine.\n",
    "        :return:\n",
    "        detections: numpy array de dimensiune NX4, unde N este numarul de detectii pentru toate imaginile.\n",
    "        detections[i, :] = [x_min, y_min, x_max, y_max]\n",
    "        scores: numpy array de dimensiune N, scorurile pentru toate detectiile pentru toate imaginile.\n",
    "        file_names: numpy array de dimensiune N, pentru fiecare detectie trebuie sa salvam numele imaginii.\n",
    "        (doar numele, nu toata calea).\n",
    "        \"\"\"\n",
    "        scales=[1.         ,0.87055,    0.75785828, 0.66069345, 0.57622779, 0.50270779,\n",
    " 0.43855988, 0.38239679, 0.33287077, 0.28877435, 0.2499512,  0.21516408,\n",
    " 0.18401213, 0.15607649, 0.13190697]\n",
    "\n",
    "        test_images_path = (self.params.dir_test_examples)\n",
    "        detections_new = None  # array cu toate detectiile pe care le obtinem\n",
    "        scores = np.array([])  # array cu toate scorurile pe care le obtinem\n",
    "        file_names_new = np.array([])  # array cu fisiele, in aceasta lista fisierele vor aparea de mai multe ori, pentru fiecare\n",
    "        # detectie din imagine, numele imaginii va aparea in aceasta lista\n",
    "        w = self.best_model.coef_.T\n",
    "        bias = self.best_model.intercept_[0]\n",
    "        num_test_images = len(detections)\n",
    "        descriptors_to_return = []\n",
    "        i=0\n",
    "        while i < (detections.shape[0]):\n",
    "            path=os.path.join(test_images_path,file_names[i])\n",
    "            start_time = timeit.default_timer()\n",
    "            print('Procesam imaginea de testare %d/%d..' % (i, num_test_images))\n",
    "            img = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "            aux=file_names[i]\n",
    "            while i<detections.shape[0] and file_names[i]==aux:\n",
    "                image_scores = np.array([])\n",
    "                image_detections = np.array([])\n",
    "                x_min, y_min, x_max, y_max=detections[i]\n",
    "                img_run=img[y_min:y_max,x_min:x_max]\n",
    "                img_c=img_run\n",
    "                ok=False\n",
    "                for scale in scales:\n",
    "                    if ok:\n",
    "                        break\n",
    "                    img_cop=self.rescale_image(img_c,scale)\n",
    "                    hog_descriptors = hog(img_run, pixels_per_cell=(self.params.dim_hog_cell, self.params.dim_hog_cell),\n",
    "                                          cells_per_block=(2, 2), feature_vector=False)\n",
    "                    num_cols = img_run.shape[1] // self.params.dim_hog_cell -1\n",
    "                    num_rows = img_run.shape[0] // self.params.dim_hog_cell -1\n",
    "                    num_cell_in_template_height = self.params.dim_window_height // self.params.dim_hog_cell-1\n",
    "                    num_cell_in_template_width= self.params.dim_window_width // self.params.dim_hog_cell-1 \n",
    "                    for y in range(0, num_rows - num_cell_in_template_height):\n",
    "                        if ok:\n",
    "                            break\n",
    "                        for x in range(0, num_cols - num_cell_in_template_width):\n",
    "                            descr = hog_descriptors[y:y + num_cell_in_template_height, x:x + num_cell_in_template_width].flatten()\n",
    "                            score = np.dot(descr, w)[0] + bias\n",
    "                            if score > self.params.threshold:\n",
    "                                '''\n",
    "                                x_min = int(x * self.params.dim_hog_cell)\n",
    "                                y_min = int(y * self.params.dim_hog_cell)\n",
    "                                x_max = int(x * self.params.dim_hog_cell + self.params.dim_window)\n",
    "                                y_max = int(y * self.params.dim_hog_cell + self.params.dim_window)\n",
    "                                '''\n",
    "                                new_box=[x_min,y_min,x_max,y_max]\n",
    "                                #cv.imshow()\n",
    "                                ok=True\n",
    "                                if image_detections.size>0:\n",
    "                                    image_detections=np.vstack([image_detections,new_box])\n",
    "                                else:\n",
    "                                    image_detections=np.array([new_box])\n",
    "                                image_scores=np.append(image_scores,score)\n",
    "                                break\n",
    "\n",
    "\n",
    "                if len(image_scores) > 0:\n",
    "                    if detections_new is None:\n",
    "                        detections_new = image_detections\n",
    "                    else:\n",
    "                        detections_new = np.concatenate((detections_new, image_detections))\n",
    "                    scores = np.append(scores, image_scores)\n",
    "                    short_name = ntpath.basename(file_names[i])\n",
    "                    image_names = [short_name for ww in range(len(image_scores))]\n",
    "                    file_names_new = np.append(file_names_new, image_names)\n",
    "                \n",
    "                i+=1\n",
    "\n",
    "\n",
    "                end_time = timeit.default_timer()\n",
    "                print('Timpul de procesarea al imaginii de testare %d/%d este %f sec.'\n",
    "                      % (i, num_test_images, end_time - start_time))\n",
    "\n",
    "        return detections_new, scores, file_names_new\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f7890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import pdb\n",
    "import ntpath\n",
    "import glob\n",
    "\n",
    "\n",
    "def show_detections_without_ground_truth(detections, scores, file_names, params: Parameters):\n",
    "    \"\"\"\n",
    "    Afiseaza si salveaza imaginile adnotate.\n",
    "    detections: numpy array de dimensiune NX4, unde N este numarul de detectii pentru toate imaginile.\n",
    "    detections[i, :] = [x_min, y_min, x_max, y_max]\n",
    "    scores: numpy array de dimensiune N, scorurile pentru toate detectiile pentru toate imaginile.\n",
    "    file_names: numpy array de dimensiune N, pentru fiecare detectie trebuie sa salvam numele imaginii.\n",
    "    (doar numele, nu toata calea).\n",
    "    \"\"\"\n",
    "    test_images_path = os.path.join(params.dir_test_examples, '*.jpg')\n",
    "    test_files = glob.glob(test_images_path)\n",
    "\n",
    "    for test_file in test_files:\n",
    "        image = cv.imread(test_file)\n",
    "        short_file_name = ntpath.basename(test_file)\n",
    "        indices_detections_current_image = np.where(file_names == short_file_name)\n",
    "        current_detections = detections[indices_detections_current_image]\n",
    "        current_scores = scores[indices_detections_current_image]\n",
    "\n",
    "        for idx, detection in enumerate(current_detections):\n",
    "            cv.rectangle(image, (detection[0], detection[1]), (detection[2], detection[3]), (0, 0, 255), thickness=1)\n",
    "            cv.putText(image, 'score:' + str(current_scores[idx])[:4], (detection[0], detection[1]),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        cv.imwrite(os.path.join(params.dir_save_files, \"detections_\" + short_file_name), image)\n",
    "        print('Apasa orice tasta pentru a continua...')\n",
    "        cv.imshow('image', np.uint8(image))\n",
    "        cv.waitKey(0)\n",
    "\n",
    "\n",
    "def show_detections_with_ground_truth(detections, scores, file_names, params: Parameters):\n",
    "    \"\"\"\n",
    "    Afiseaza si salveaza imaginile adnotate. Deseneaza bounding box-urile prezice si cele corecte.\n",
    "    detections: numpy array de dimensiune NX4, unde N este numarul de detectii pentru toate imaginile.\n",
    "    detections[i, :] = [x_min, y_min, x_max, y_max]\n",
    "    scores: numpy array de dimensiune N, scorurile pentru toate detectiile pentru toate imaginile.\n",
    "    file_names: numpy array de dimensiune N, pentru fiecare detectie trebuie sa salvam numele imaginii.\n",
    "    (doar numele, nu toata calea).\n",
    "    \"\"\"\n",
    "\n",
    "    ground_truth_bboxes = np.loadtxt(params.path_annotations, dtype='str')\n",
    "    test_images_path = os.path.join(params.dir_test_examples, '*.jpg')\n",
    "    test_files = glob.glob(test_images_path)\n",
    "\n",
    "    for test_file in test_files:\n",
    "        image = cv.imread(test_file)\n",
    "        short_file_name = ntpath.basename(test_file)\n",
    "        indices_detections_current_image = np.where(file_names == short_file_name)\n",
    "        current_detections = detections[indices_detections_current_image]\n",
    "        current_scores = scores[indices_detections_current_image]\n",
    "\n",
    "        for idx, detection in enumerate(current_detections):\n",
    "            cv.rectangle(image, (detection[0], detection[1]), (detection[2], detection[3]), (0, 0, 255), thickness=1)\n",
    "            cv.putText(image, 'score:' + str(current_scores[idx])[:4], (detection[0], detection[1]),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        annotations = ground_truth_bboxes[ground_truth_bboxes[:, 0] == short_file_name]\n",
    "\n",
    "        # show ground truth bboxes\n",
    "        for detection in annotations:\n",
    "            cv.rectangle(image, (int(detection[1]), int(detection[2])), (int(detection[3]), int(detection[4])), (0, 255, 0), thickness=1)\n",
    "\n",
    "        cv.imwrite(os.path.join(params.dir_save_files, \"detections_\" + short_file_name), image)\n",
    "        print('Apasa orice tasta pentru a continua...')\n",
    "        cv.imshow('image', np.uint8(image))\n",
    "        cv.waitKey(0)\n",
    "        \n",
    "        \n",
    "def eval_detections_character(detections, scores, file_names,ground_truth_path,character):\n",
    "    ground_truth_file = np.loadtxt(ground_truth_path, dtype='str')\n",
    "    ground_truth_file_names = np.array(ground_truth_file[:, 0])\n",
    "    ground_truth_detections = np.array(ground_truth_file[:, 1:], int)\n",
    "\n",
    "    num_gt_detections = len(ground_truth_detections)  # numar total de adevarat pozitive\n",
    "    gt_exists_detection = np.zeros(num_gt_detections)\n",
    "    # sorteazam detectiile dupa scorul lor\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    file_names = file_names[sorted_indices]\n",
    "    scores = scores[sorted_indices]\n",
    "    detections = detections[sorted_indices]\n",
    "\n",
    "    num_detections = len(detections)\n",
    "    true_positive = np.zeros(num_detections)\n",
    "    false_positive = np.zeros(num_detections)\n",
    "    duplicated_detections = np.zeros(num_detections)\n",
    "\n",
    "    for detection_idx in range(num_detections):\n",
    "        indices_detections_on_image = np.where(ground_truth_file_names == file_names[detection_idx])[0]\n",
    "\n",
    "        gt_detections_on_image = ground_truth_detections[indices_detections_on_image]\n",
    "        bbox = detections[detection_idx]\n",
    "        max_overlap = -1\n",
    "        index_max_overlap_bbox = -1\n",
    "        for gt_idx, gt_bbox in enumerate(gt_detections_on_image):\n",
    "            overlap = facial_detector.intersection_over_union(bbox, gt_bbox)\n",
    "            if overlap > max_overlap:\n",
    "                max_overlap = overlap\n",
    "                index_max_overlap_bbox = indices_detections_on_image[gt_idx]\n",
    "\n",
    "        # clasifica o detectie ca fiind adevarat pozitiva / fals pozitiva\n",
    "        if max_overlap >= 0.3:\n",
    "            if gt_exists_detection[index_max_overlap_bbox] == 0:\n",
    "                true_positive[detection_idx] = 1\n",
    "                gt_exists_detection[index_max_overlap_bbox] = 1\n",
    "            else:\n",
    "                false_positive[detection_idx] = 1\n",
    "                duplicated_detections[detection_idx] = 1\n",
    "        else:\n",
    "            false_positive[detection_idx] = 1\n",
    "\n",
    "    cum_false_positive = np.cumsum(false_positive)\n",
    "    cum_true_positive = np.cumsum(true_positive)\n",
    "\n",
    "    rec = cum_true_positive / num_gt_detections\n",
    "    prec = cum_true_positive / (cum_true_positive + cum_false_positive)\n",
    "    average_precision = facial_detector.compute_average_precision(rec, prec)\n",
    "    plt.plot(rec, prec, '-')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(character + ' faces: average precision %.3f' % average_precision)\n",
    "    plt.savefig('precizie_medie_' + character + '.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57dff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params: Parameters = Parameters()\n",
    "params.dim_window=36\n",
    "params.dim_window_width = 36\n",
    "params.dim_window_height = 36# exemplele pozitive (fete de oameni cropate) au 36x36 pixeli\n",
    "params.dim_hog_cell = 6  # dimensiunea celulei\n",
    "params.overlap = 0.3\n",
    "params.number_positive_examples = 6977  # numarul exemplelor pozitive\n",
    "params.number_negative_examples = 72283  # numarul exemplelor negative\n",
    "\n",
    "params.threshold = 0 # toate ferestrele cu scorul > threshold si maxime locale devin detectii\n",
    "params.has_annotations = True\n",
    "\n",
    "params.use_hard_mining = False  # (optional)antrenare cu exemple puternic negative\n",
    "params.use_flip_images = True  # adauga imaginile cu fete oglindite\n",
    "\n",
    "if params.use_flip_images:\n",
    "    params.number_positive_examples *= 2\n",
    "\n",
    "facial_detector: FacialDetector = FacialDetector(params)\n",
    "#good=facial_detector.get_positive_examples()\n",
    "#bad=facial_detector.get_negative_examples()\n",
    "#print(len(good),len(bad))\n",
    "\n",
    "# Pasii 1+2+3. Incarcam exemplele pozitive (cropate) si exemple negative generate\n",
    "# verificam daca sunt deja existente\n",
    "positive_features_path = os.path.join(params.dir_save_files, 'descriptoriExemplePozitive_' + str(params.dim_hog_cell) + '_' +\n",
    "                        str(params.number_positive_examples) + '.npy')\n",
    "if os.path.exists(positive_features_path):\n",
    "    positive_features = np.load(positive_features_path)\n",
    "    print('Am incarcat descriptorii pentru exemplele pozitive',len(positive_features))\n",
    "else:\n",
    "    print('Construim descriptorii pentru exemplele pozitive:')\n",
    "    positive_features = facial_detector.get_positive_descriptors()\n",
    "    np.save(positive_features_path, positive_features)\n",
    "    print('Am salvat descriptorii pentru exemplele pozitive in fisierul %s' % positive_features_path)\n",
    "\n",
    "# exemple negative\n",
    "negative_features_path = os.path.join(params.dir_save_files, 'descriptoriExempleNegative_' + str(params.dim_hog_cell) + '_' +\n",
    "                        str(params.number_negative_examples) + '.npy')\n",
    "if os.path.exists(negative_features_path):\n",
    "    negative_features = np.load(negative_features_path)\n",
    "    print('Am incarcat descriptorii pentru exemplele negative')\n",
    "else:\n",
    "    print('Construim descriptorii pentru exemplele negative:')\n",
    "    negative_features = facial_detector.get_extra_descriptors()\n",
    "    np.save(negative_features_path, negative_features)\n",
    "    print('Am salvat descriptorii pentru exemplele negative in fisierul %s' % negative_features_path)\n",
    "\n",
    "# Pasul 4. Invatam clasificatorul liniar\n",
    "print(\"Positive Features Shape:\", np.squeeze(positive_features).shape)\n",
    "print(\"Negative Features Shape:\", np.squeeze(negative_features).shape)\n",
    "\n",
    "training_examples = np.concatenate((np.squeeze(positive_features), np.squeeze(negative_features)), axis=0)\n",
    "train_labels = np.concatenate((np.ones(positive_features.shape[0]), np.zeros(np.array(negative_features).shape[0])))\n",
    "#print(len(np.ones(params.number_positive_examples)), len(np.zeros(negative_features.shape[0])))\n",
    "facial_detector.train_classifier(training_examples, train_labels)\n",
    "\n",
    "# Pasul 5. (optional) Antrenare cu exemple puternic negative (detectii cu scor >0 din cele 274 de imagini negative)\n",
    "# Daca implementati acest pas ar trebui sa modificati functia FacialDetector.run()\n",
    "# astfel incat sa va returneze descriptorii detectiilor cu scor > 0 din cele 274 imagini negative\n",
    "# completati codul in continuare\n",
    "# TODO:  (optional)  completeaza codul in continuare\n",
    "\n",
    "detections, scores, file_names = facial_detector.run()\n",
    "np.save(os.path.join(params.sol_path, \"task1/detections_all_faces.npy\"), detections)\n",
    "np.save(os.path.join(params.sol_path, \"task1/scores_all_faces.npy\"), scores)\n",
    "np.save(os.path.join(params.sol_path, \"task1/file_names_all_faces.npy\"), file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908d7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(person):\n",
    "    params.dir_pos_examples=os.path.join(params.base_dir, \"exemplePozitive\")\n",
    "    if person ==\"fred\":\n",
    "        params.dim_window_width = 36\n",
    "        params.dim_window_height = 48\n",
    "        params.number_positive_examples=2\n",
    "        params.dim_hog_cell=6\n",
    "        params.number_negative_examples =  67511\n",
    "    if person ==\"barney\":\n",
    "        params.dim_window_width = 36\n",
    "        params.dim_window_height = 36\n",
    "        params.number_positive_examples=13954\n",
    "        params.dim_hog_cell=6\n",
    "        params.number_negative_examples =  72283\n",
    "    if person ==\"wilma\":\n",
    "        params.dim_window_width = 36\n",
    "        params.dim_window_height = 48\n",
    "        params.number_positive_examples=1\n",
    "        params.dim_hog_cell=4\n",
    "        params.number_negative_examples =  67511\n",
    "    if person ==\"betty\":\n",
    "        params.dim_window_width = 36\n",
    "        params.dim_window_height = 48\n",
    "        params.number_positive_examples=1\n",
    "        params.dim_hog_cell=4\n",
    "        params.number_negative_examples =  67511\n",
    "        \n",
    "    params.threshold=0\n",
    "    positive_features_path = os.path.join(params.dir_save_files, 'descriptoriExemplePozitive_' +person+'_'+ str(params.dim_hog_cell) + '_' +\n",
    "                            str(params.number_positive_examples) + '.npy')\n",
    "    if os.path.exists(positive_features_path):\n",
    "        positive_features_2 = np.load(positive_features_path)\n",
    "        print('Am incarcat descriptorii pentru exemplele pozitive',len(positive_features))\n",
    "    else:\n",
    "        print('Construim descriptorii pentru exemplele pozitive:')\n",
    "        positive_features_2 = facial_detector.get_poz_person_descriptors(person)\n",
    "        np.save(positive_features_path, positive_features_2)\n",
    "        print('Am salvat descriptorii pentru exemplele pozitive in fisierul %s' % positive_features_path)\n",
    "        \n",
    "        \n",
    "    print((np.squeeze(positive_features_2).shape,\"aici\"))\n",
    "    # exemple negative\n",
    "    negative_features_path = os.path.join(params.dir_save_files, 'descriptoriExempleNegative_' +person+'_'+ str(params.dim_hog_cell) + '_' +\n",
    "                            str(params.number_negative_examples) + '.npy')\n",
    "    if os.path.exists(negative_features_path):\n",
    "        negative_features_2 = np.load(negative_features_path)\n",
    "        print('Am incarcat descriptorii pentru exemplele negative')\n",
    "    else:\n",
    "        print('Construim descriptorii pentru exemplele negative:')\n",
    "        negative_features_2 = facial_detector.get_neg_person_descriptors(person,negative_features)\n",
    "        np.save(negative_features_path, negative_features_2)\n",
    "        print('Am salvat descriptorii pentru exemplele negative in fisierul %s' % negative_features_path)\n",
    "        \n",
    "    print((np.squeeze(negative_features_2).shape,\"aici\"))\n",
    "    \n",
    "    training_examples = np.concatenate((np.squeeze(positive_features_2), np.squeeze(negative_features_2)), axis=0)\n",
    "    train_labels = np.concatenate((np.ones(positive_features_2.shape[0]), np.zeros(np.array(negative_features_2).shape[0])))\n",
    "    facial_detector.train_classifier(training_examples, train_labels,person)\n",
    "    detections2, scores2, file_names2 = facial_detector.run()\n",
    "    np.save(os.path.join(params.sol_path, f\"task2/detections_{person}.npy\"), detections2)\n",
    "    np.save(os.path.join(params.sol_path, f\"task2/scores_{person}.npy\"), scores2)\n",
    "    np.save(os.path.join(params.sol_path, f\"task2/file_names_{person}.npy\"), file_names2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(\"fred\")\n",
    "run(\"barney\")\n",
    "run(\"betty\")\n",
    "run(\"wilma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c86cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results_task1(solution_path,ground_truth_path,verbose = 0):\n",
    "\n",
    "\t#incarca detectiile + scorurile + numele de imagini\t\n",
    "\tdetections = np.load(solution_path + \"detections_all_faces.npy\",allow_pickle=True,fix_imports=True,encoding='latin1')\n",
    "\tprint(detections.shape)\n",
    "\n",
    "\tscores = np.load(solution_path + \"scores_all_faces.npy\",allow_pickle=True,fix_imports=True,encoding='latin1')\n",
    "\tprint(scores.shape)\n",
    "\t\n",
    "\tfile_names = np.load(solution_path + \"file_names_all_faces.npy\",allow_pickle=True,fix_imports=True,encoding='latin1')\n",
    "\tprint(file_names.shape)\n",
    "\n",
    "\tfacial_detector.eval_detections(detections, scores, file_names, ground_truth_path)\n",
    "\n",
    "def evaluate_results_task2(solution_path,ground_truth_path,character, verbose = 0):\n",
    "\n",
    "\t#incarca detectiile + scorurile + numele de imagini\t\n",
    "\tdetections = np.load(solution_path + \"detections_\" + character + \".npy\",allow_pickle=True,fix_imports=True,encoding='latin1')\n",
    "\tprint(detections.shape)\n",
    "\n",
    "\tscores = np.load(solution_path + \"scores_\"+ character + \".npy\",allow_pickle=True,fix_imports=True,encoding='latin1')\n",
    "\tprint(scores.shape)\n",
    "\t\n",
    "\tfile_names = np.load(solution_path + \"file_names_\"+ character + \".npy\",allow_pickle=True,fix_imports=True,encoding='latin1')\n",
    "\tprint(file_names.shape)\n",
    "\n",
    "\teval_detections_character(detections, scores, file_names, ground_truth_path, character)\n",
    "  \n",
    "\n",
    "verbose = 0\n",
    "\n",
    "#change this on your machine\n",
    "solution_path_root = params.sol_path\n",
    "ground_truth_path_root = \"validare/\"\n",
    "\n",
    "\n",
    "#task1\n",
    "solution_path = solution_path_root + \"task1/\"\n",
    "ground_truth_path = ground_truth_path_root + \"task1_gt_validare.txt\"\n",
    "print(solution_path)\n",
    "evaluate_results_task1(solution_path, ground_truth_path, verbose)\n",
    "\n",
    "#pdb.set_trace()\n",
    "\n",
    "#task2\n",
    "solution_path = solution_path_root + \"task2/\"\n",
    "\n",
    "\n",
    "ground_truth_path = ground_truth_path_root + \"task2_fred_gt_validare.txt\"\n",
    "evaluate_results_task2(solution_path, ground_truth_path, \"fred\", verbose)\n",
    "\n",
    "ground_truth_path = ground_truth_path_root + \"task2_barney_gt_validare.txt\"\n",
    "evaluate_results_task2(solution_path, ground_truth_path, \"barney\", verbose)\n",
    "\n",
    "ground_truth_path = ground_truth_path_root + \"task2_betty_gt_validare.txt\"\n",
    "evaluate_results_task2(solution_path, ground_truth_path, \"betty\", verbose)\n",
    "\n",
    "ground_truth_path = ground_truth_path_root + \"task2_wilma_gt_validare.txt\"\n",
    "evaluate_results_task2(solution_path, ground_truth_path, \"wilma\", verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1568e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_yolo_2():\n",
    "    image_width=480\n",
    "    image_height=360\n",
    "    people=[\"fred\",\"barney\",\"wilma\",\"betty\"]\n",
    "    nr=0\n",
    "    for person in people:\n",
    "        i=1\n",
    "        j=0\n",
    "        folder_path = f\"{params.base_dir}{person}\"\n",
    "        annotations_path=f\"{params.base_dir}{person}_annotations.txt\"\n",
    "        with open(annotations_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        files = os.listdir(folder_path)\n",
    "        for file in files:\n",
    "            text_data=\"\"\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            img=cv.imread(file_path)\n",
    "            i_str=str(i)\n",
    "            cv.imwrite(f\"C:/Users/rares/darknet-master/build/darknet/x64/data/obj/{nr*1000+i}.jpg\",img)\n",
    "            while len(i_str)<4:\n",
    "                i_str=\"0\"+i_str\n",
    "            while j<len(lines) and lines[j][0:4]==i_str:\n",
    "                poz=lines[j].split()[1:5]\n",
    "                if lines[j].split()[5]!=\"unknown\":\n",
    "                    for q in range(len(poz)):\n",
    "                        poz[q]=int(poz[q])\n",
    "                    xmin,ymin,xmax,ymax=poz\n",
    "\n",
    "                    x_center = (xmin + xmax) / 2.0\n",
    "                    y_center = (ymin + ymax) / 2.0\n",
    "                    box_width = xmax - xmin\n",
    "                    box_height = ymax - ymin\n",
    "\n",
    "                    x_center /= image_width\n",
    "                    y_center /= image_height\n",
    "                    box_width /= image_width\n",
    "                    box_height /= image_height\n",
    "\n",
    "                    text_data+=str(people.index(lines[j].split()[5]))+\" \"+str(x_center)+\" \"+str(y_center)+\" \"+str(box_width)+\" \"+str(box_height)+\"\\n\"\n",
    "                j+=1\n",
    "                    \n",
    "                \n",
    "    \n",
    "\n",
    "            text_data=text_data[:-1]\n",
    "            with open(f\"C:/Users/rares/darknet-master/build/darknet/x64/data/obj/{nr*1000+i}.txt\", 'w') as file:\n",
    "                file.write(text_data)\n",
    "            i+=1\n",
    "        nr+=1\n",
    "        \n",
    "\n",
    "def to_yolo_1():\n",
    "    image_width=480\n",
    "    image_height=360\n",
    "    people=[\"fred\",\"barney\",\"wilma\",\"betty\"]\n",
    "    nr=0\n",
    "    for person in people:\n",
    "        i=1\n",
    "        j=0\n",
    "        folder_path = f\"{params.base_dir}{person}\"\n",
    "        annotations_path=f\"{params.base_dir}{person}_annotations.txt\"\n",
    "        with open(annotations_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        files = os.listdir(folder_path)\n",
    "        for file in files:\n",
    "            text_data=\"\"\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            img=cv.imread(file_path)\n",
    "            i_str=str(i)\n",
    "            cv.imwrite(f\"C:/Users/rares/darknet-master/build/darknet/x64/data/obj/{nr*1000+i}.jpg\",img)\n",
    "            while len(i_str)<4:\n",
    "                i_str=\"0\"+i_str\n",
    "            while j<len(lines) and lines[j][0:4]==i_str:\n",
    "                poz=lines[j].split()[1:5]\n",
    "                for q in range(len(poz)):\n",
    "                    poz[q]=int(poz[q])\n",
    "                xmin,ymin,xmax,ymax=poz\n",
    "\n",
    "                x_center = (xmin + xmax) / 2.0\n",
    "                y_center = (ymin + ymax) / 2.0\n",
    "                box_width = xmax - xmin\n",
    "                box_height = ymax - ymin\n",
    "\n",
    "                x_center /= image_width\n",
    "                y_center /= image_height\n",
    "                box_width /= image_width\n",
    "                box_height /= image_height\n",
    "\n",
    "                text_data+=str(0)+\" \"+str(x_center)+\" \"+str(y_center)+\" \"+str(box_width)+\" \"+str(box_height)+\"\\n\"\n",
    "                j+=1\n",
    "                    \n",
    "                \n",
    "\n",
    "            text_data=text_data[:-1]\n",
    "            with open(f\"C:/Users/rares/darknet-master/build/darknet/x64/data/obj/{nr*1000+i}.txt\", 'w') as file:\n",
    "                file.write(text_data)\n",
    "            i+=1\n",
    "        nr+=1\n",
    "               \n",
    "def train_path():\n",
    "    text_data=\"\"\n",
    "    for i in range(1,4001):\n",
    "        text_data+=f\"data/obj/{i}.jpg\"+\"\\n\"\n",
    "    text_data=text_data[:-1]\n",
    "    with open(f\"C:/Users/rares/darknet-master/build/darknet/x64/data/train.txt\", 'w') as file:\n",
    "            file.write(text_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04275c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_yolo_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_yolo_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90570146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_run_2(person):\n",
    "    net = cv.dnn.readNet(\"C:/Users/rares/Downloads/yolov4-flintstone_last_2.weights\", \"C:/Users/rares/darknet/yolov4-flintstone-2.cfg\")\n",
    "    classes = []\n",
    "    with open(\"C:/Users/rares/darknet/data/obj.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "    validation_folder = params.dir_test_examples\n",
    "    detections = None  # array cu toate detectiile pe care le obtinem\n",
    "    scores = np.array([])  # array cu toate scorurile pe care le obtinem\n",
    "    file_names = np.array([])\n",
    "    \n",
    "    test_images_path = os.path.join(params.dir_test_examples, '*.jpg')\n",
    "    test_files = glob.glob(test_images_path)\n",
    "    i=0\n",
    "\n",
    "    for file in os.listdir(validation_folder):\n",
    "        start_time = timeit.default_timer()\n",
    "        image_path = os.path.join(validation_folder, file)\n",
    "        img = cv.imread(image_path)\n",
    "        height, width, _ = img.shape\n",
    "        blob = cv.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(layer_names)\n",
    "        image_scores = np.array([])\n",
    "        image_detections = np.array([])\n",
    "\n",
    "        # Process the output\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                result = detection[5:]\n",
    "                class_id = np.argmax(result)\n",
    "                confidence = result[class_id]\n",
    "                if confidence > 0.0 and classes[class_id]==person:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x_min = max(0, int(center_x - w / 2))\n",
    "                    y_min = max(0, int(center_y - h / 2))\n",
    "                    x_max = min(width, int(center_x + w / 2))\n",
    "                    y_max = min(height, int(center_y + h / 2))\n",
    "\n",
    "                    box=[x_min,y_min,x_max,y_max]\n",
    "                    #cv.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                    #cv.putText(img, classes[class_id], (x_min, y_min - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    #cv.imshow(\"\",img)\n",
    "                    cv.waitKey(0)\n",
    "                    if image_detections.size>0:\n",
    "                        image_detections=np.vstack([image_detections,box])\n",
    "                    else:\n",
    "                        image_detections=np.array([box])\n",
    "                    image_scores=np.append(image_scores,confidence)\n",
    "        if len(image_scores) > 0:\n",
    "            image_detections, image_scores = facial_detector.non_maximal_suppression(np.array(image_detections),\n",
    "                                                                          np.array(image_scores), img.shape)\n",
    "\n",
    "        \n",
    "        if len(image_scores) > 0:\n",
    "            if detections is None:\n",
    "                detections = image_detections\n",
    "            else:\n",
    "                detections = np.concatenate((detections, image_detections))\n",
    "            scores = np.append(scores, image_scores)\n",
    "            short_name = ntpath.basename(test_files[i])\n",
    "            image_names = [short_name for ww in range(len(image_scores))]\n",
    "            file_names = np.append(file_names, image_names)\n",
    "        i+=1\n",
    "        end_time = timeit.default_timer()\n",
    "        print('Timpul de procesarea al imaginii de testare %d/%d este %f sec.'\n",
    "              % (i,200, end_time - start_time))\n",
    "        \n",
    "    np.save(os.path.join(params.sol_path, f\"bonus_task2/detections_{person}.npy\"), detections)\n",
    "    np.save(os.path.join(params.sol_path, f\"bonus_task2/scores_{person}.npy\"), scores)\n",
    "    np.save(os.path.join(params.sol_path, f\"bonus_task2/file_names_{person}.npy\"), file_names)\n",
    "\n",
    "\n",
    "    return detections, scores, file_names\n",
    "                          \n",
    "ground_truth_path = \"validare/\" + \"task2_betty_gt_validare.txt\" \n",
    "detections4,scores4,file_names4=yolo_run_2(\"Betty\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01483ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_detections_character(detections4,scores4,file_names4,ground_truth_path,\"Betty\")\n",
    "show_detections_without_ground_truth(detections4, scores4, file_names4, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a12cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_run_1():\n",
    "    net = cv.dnn.readNet(\"C:/Users/rares/Downloads/yolov4-flintstone-1_1000.weights\", \"C:/Users/rares/darknet/yolov4-flintstone-1.cfg\")\n",
    "    classes = []\n",
    "    with open(\"C:/Users/rares/darknet/data/obj.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "    validation_folder = params.dir_test_examples\n",
    "    detections = None  # array cu toate detectiile pe care le obtinem\n",
    "    scores = np.array([])  # array cu toate scorurile pe care le obtinem\n",
    "    file_names = np.array([])\n",
    "    \n",
    "    test_images_path = os.path.join(params.dir_test_examples, '*.jpg')\n",
    "    test_files = glob.glob(test_images_path)\n",
    "    i=0\n",
    "\n",
    "    for file in os.listdir(validation_folder):\n",
    "        start_time = timeit.default_timer()\n",
    "        image_path = os.path.join(validation_folder, file)\n",
    "        img = cv.imread(image_path)\n",
    "        height, width, _ = img.shape\n",
    "        blob = cv.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(layer_names)\n",
    "        image_scores = np.array([])\n",
    "        image_detections = np.array([])\n",
    "\n",
    "        # Process the output\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                result = detection[5:]\n",
    "                class_id = np.argmax(result)\n",
    "                confidence = result[class_id]\n",
    "                if confidence > 0.0:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x_min = max(0, int(center_x - w / 2))\n",
    "                    y_min = max(0, int(center_y - h / 2))\n",
    "                    x_max = min(width, int(center_x + w / 2))\n",
    "                    y_max = min(height, int(center_y + h / 2))\n",
    "\n",
    "                    box=[x_min,y_min,x_max,y_max]\n",
    "                    #cv.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                    #cv.putText(img, classes[class_id], (x_min, y_min - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    if image_detections.size>0:\n",
    "                        image_detections=np.vstack([image_detections,box])\n",
    "                    else:\n",
    "                        image_detections=np.array([box])\n",
    "                    image_scores=np.append(image_scores,confidence)\n",
    "        if len(image_scores) > 0:\n",
    "            image_detections, image_scores = facial_detector.non_maximal_suppression(np.array(image_detections),\n",
    "                                                                          np.array(image_scores), img.shape)\n",
    "\n",
    "        \n",
    "        if len(image_scores) > 0:\n",
    "            if detections is None:\n",
    "                detections = image_detections\n",
    "            else:\n",
    "                detections = np.concatenate((detections, image_detections))\n",
    "            scores = np.append(scores, image_scores)\n",
    "            short_name = ntpath.basename(test_files[i])\n",
    "            image_names = [short_name for ww in range(len(image_scores))]\n",
    "            file_names = np.append(file_names, image_names)\n",
    "        i+=1\n",
    "        end_time = timeit.default_timer()\n",
    "        print('Timpul de procesarea al imaginii de testare %d/%d este %f sec.'\n",
    "              % (i,200, end_time - start_time))\n",
    "\n",
    "\n",
    "    np.save(os.path.join(params.sol_path, f\"bonus_task1/detections.npy\"), detections)\n",
    "    np.save(os.path.join(params.sol_path, f\"task2/scores.npy\"), scores)\n",
    "    np.save(os.path.join(params.sol_path, f\"task2/file_names.npy\"), file_names)\n",
    "    return detections, scores, file_names\n",
    "                          \n",
    "ground_truth_path = ground_truth_path_root + \"task1_gt_validare.txt\"             \n",
    "detections4, scores4, file_names4 = yolo_run_1()\n",
    "facial_detector.eval_detections(detections4,scores4,file_names4,ground_truth_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1301651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d523d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
